{"cells":[{"cell_type":"markdown","metadata":{"id":"GXRkf66ekryN"},"source":["#<center> LANGUAGE MODELING WITH RNN </center>\n","---\n","\n","<div align=\"right\"> Laura Corso </div>\n","<div align=\"right\">MAT. 230485</div>"]},{"cell_type":"markdown","metadata":{"id":"R9cZdURglcbp"},"source":["In this code is presented a **baseline Language Model** followed by its **improvement** through some *regularization techniques*. \n","\n","In particular, the used regularization techniques include: \n","\n","*   *dropout* applied to hidden-to-hidden connections of the RNN\n","*   *Variational dropout* (see the work by [Merity et al.](https://arxiv.org/abs/1708.02182)).\n","\n","</br>\n","\n","The model is trained and tested on the **Penn Tree bank dataset** ([download in .zip](https://deepai.org/dataset/penn-treebank)).\n","\n","</br>\n","\n","The improvement of baseline model were inspired by the following codes:\n","\n","1.   [LSTM and QRNN Language Model Toolkit](https://github.com/salesforce/awd-lstm-lm)\n","2.   [Hedwig](https://github.com/castorini/hedwig)\n","3.   [Breaking the Softmax Bottleneck: A High-Rank RNN Language Model](https://arxiv.org/abs/1711.03953)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RG0UbSYNLJwj"},"outputs":[],"source":["# Imports\n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import torch.optim as optim\n","from os import path, mkdir\n","from collections import Counter\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import math\n","import random\n","from shutil import unpack_archive as unzip\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tFp695hNzWiN"},"outputs":[],"source":["# Global variables\n","device = 'cuda:0'\n","PAD_TOKEN = 0\n","BATCH_SIZE = 64\n","PATH = '/content/gdrive/MyDrive/NLU/Final/' # path in which the .zip of the dataset is located and\n","                                            # in which the final results of this code will be saved\n","SAVE = PATH + \"Results/\"\n","HD_SIZE = 200                               # size of the hidden layers of the RNN\n","EMB_DIM = 300                               # size of embedding\n","LEARNING_RATE_B = 0.0001                    # lr for the baseline model\n","LEARNING_RATE_I = 0.001                     # lr for the improved model\n","RUNS = 5                                    # number of runs\n","EPOCHS_B = 30                               # number of epochs for the baseline model\n","EPOCHS_I = 40                               # number of epochs for the improved model\n","PATIENCE = 3                                # early stopping parameter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIB9V3vyp1jo"},"outputs":[],"source":["# Seeds in order to make this code reproducible\n","torch.manual_seed(5)\n","random.seed(5)\n","np.random.seed(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17629,"status":"ok","timestamp":1658344785639,"user":{"displayName":"Laura Corso","userId":"16642028059811970306"},"user_tz":-120},"id":"0FCUj_ogBfWO","outputId":"0f32b304-9508-4221-fdd4-1ec3bbaa7f6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Mount of the Google Drive folder\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"gIVbHnLS0x77"},"source":["# Load data from the dataset Penn Treebank Corpus"]},{"cell_type":"markdown","metadata":{"id":"7tvJSlJzqkIG"},"source":["The dataset is composed of 3 file: one for the train set, one for the test set and one for the valid set. Each one is composed of sentences: one sentence for every line."]},{"cell_type":"markdown","metadata":{"id":"wWo-zrUKjpYI"},"source":["* Preparation of the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ERasFUE1CKan"},"outputs":[],"source":["# Unzip the dataset\n","if not path.exists(path.join(PATH, \"Dataset/\")):\n","  unzip(path.join(PATH, \"ptbdataset.zip\"), path.join(PATH, \"Dataset/\"))\n","\n","# Creation of the folder to save the results\n","if not path.exists(SAVE):\n","  mkdir(SAVE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TIYD60jV0wPh"},"outputs":[],"source":["\"\"\"\n","Class that contains all the words in the corpus along with their ids.\n",":attribute word2id: dictionary composed of {word: id}\n",":attribute id2word: dictionary composed of {id: word}\n","\"\"\"\n","class Corpus():\n","  def __init__(self, sents):\n","    words = []\n","    for sent in sents:\n","      for word in sent.split():\n","        words.append(word)\n","    self.word2id = self.w2id(words)\n","    self.id2word = {id: word for word, id in self.word2id.items()}\n","\n","\n","  \"\"\"\n","  Method used to convert each word into the corresponding id.\n","  :param wds: list of words to convert\n","  :return vocab: dictionary containing for each word its id\n","  \"\"\"\n","  def w2id(self, wds):\n","    vocab = {'pad': PAD_TOKEN} # the pad is mapped to 0\n","\n","    # Mapping of each word\n","    count = Counter(wds)\n","    for k, word in count.items():\n","      vocab[k] = len(vocab)\n","\n","    return vocab\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctEgzZwd9gxP"},"outputs":[],"source":["\"\"\"\n","Function that load the sentences from the specified .txt file.\n",":param path: path of the .txt file in which the sentences are contained\n",":return sents: list of the sentences contained in the specified file\n","\"\"\"\n","def load_raw_data(path):\n","  with open(path, 'r') as f:\n","    sents = []\n","    for line in f:\n","      sents.append(line + '<eos>')\n","\n","    return sents\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLRG1ksJBW2L"},"outputs":[],"source":["# Load the raw data and organize them into a Corpus\n","trainSet = load_raw_data(path.join(PATH, \"Dataset/ptb.train.txt\"))\n","testSet = load_raw_data(path.join(PATH, \"Dataset/ptb.test.txt\"))\n","validSet = load_raw_data(path.join(PATH, \"Dataset/ptb.valid.txt\"))\n","\n","trainCorpus = Corpus(trainSet)\n","testCorpus = Corpus(testSet)\n","validCorpus = Corpus(validSet)"]},{"cell_type":"markdown","metadata":{"id":"TbLaC0twj8mj"},"source":["* Preparation of the data to use in the Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d2dKgOGaInfA"},"outputs":[],"source":["\"\"\"\n","Function that create a customed pytorch dataset.\n",":attribute sents: list that contains all the sentences of the dataset\n",":attribute wordIds: list that contains the sentences in which the words are replaced by their ids\n","\"\"\"\n","class PennTreeBankD(data.Dataset):\n","  def __init__(self, dataset, corpus):\n","    self.sents = []\n","    self.wordIds = []\n","    for sent in dataset:\n","      self.sents.append(sent)\n","    self.wordIds = self.wordMap(self.sents, corpus.word2id)\n","\n","  def __getitem__(self, index):\n","    return torch.Tensor(self.wordIds[index])\n","\n","  def __len__(self):\n","    return len(self.sents)\n","\n","  \"\"\"\n","  Method that returns the list of lists of integers to which each word of each sentence has been mapped to.\n","  :param stns: list of the sentences in the dataset\n","  :param mapper: dictionary {word: id}\n","  :return maps: list of lists of the ids of the words in the dataset\n","  \"\"\"\n","  def wordMap(self, stns, mapper):\n","    maps = []\n","\n","    for sent in stns:\n","      seq = []\n","      for word in sent.split():\n","        if word in mapper:\n","          seq.append(mapper[word])\n","        else:\n","          seq.append(mapper['<unk>'])\n","\n","      maps.append(seq)\n","\n","    return maps\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q5cTgEhoNYm_"},"outputs":[],"source":["# Creation of the three datasets\n","train_dataset = PennTreeBankD(trainSet, trainCorpus)\n","test_dataset = PennTreeBankD(testSet, trainCorpus) # map the words of the testSet with the ids of the training corpus\n","valid_dataset = PennTreeBankD(validSet, trainCorpus) # map the words of the validSet with the ids of the training corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oI2_fmSoPl7_"},"outputs":[],"source":["\"\"\"\n","Definition of a custom collate_fn function to use in the dataloader to handle padding.\n",":param batch: current batch extracted by the dataloader\n",":return: padded input sentences\n",":return: lenght of each input sentences (without padding)\n",":return: padded target sentences\n",":return: lenght of each target sentences (without padding)\n","\"\"\"\n","def collate_fn(batch):\n","\n","\n","  \"\"\"\n","  Function that unify in a matrix all the padded sentences of the batch. \n","  It is applied a right padding in order to obtain sentences that are long as the longest one.\n","  :param sents: list of setnences of the batch\n","  :return padded_sents: tensor [n_sentences, maximum_length] containing the padded sentences\n","  \"\"\"\n","  def sentPad(sents):\n","    lengths = [len(sent) for sent in sents] # list containing the length of each sentence of the dataset\n","\n","    # Extract the maximum length. It will be used as the reference length for each sentence\n","    if max(lengths) == 0:\n","      max_len = 1\n","    else:\n","      max_len = max(lengths)\n","\n","    # Tensor [n_sentences, maximum_length] containing the padded sentences\n","    padded_sents = torch.LongTensor(len(sents), max_len).fill_(PAD_TOKEN)\n","\n","    for idx, sent in enumerate(sents):\n","      padded_sents[idx, :len(sent)] = sent\n","\n","    padded_sents.detach()\n","\n","    return padded_sents, lengths\n","\n","  # Sort the batch in order of increasing sentence's length --> the dataloader \n","  # will load, for each batch, the sentences in order of length\n","  batch.sort(key = lambda x: len(x), reverse = True)\n","  sequences = [wordId for wordId in batch] # extract the word ids of the batch\n","\n","  # Create the target and input sequences. \n","  targets = [] # list that contains the target sequences --> sequences that start from the second word\n","  s = [] # list that contains the input sequences --> sequences that have the last word removed\n","  for seq in sequences:\n","    targets.append(seq[1:])\n","    s.append(seq[:-1])\n","\n","  ps, ls = sentPad(s) # pad the sequences of word ids\n","  pt, lt = sentPad(targets) # pad the target sequences of word ids\n","\n","  return ps.to(device), torch.LongTensor(ls).to(device), pt.to(device), torch.LongTensor(lt).to(device)\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Wa0y1GcjR3Q"},"outputs":[],"source":["# Instantiation of the DataLoaders\n","# Each DataLoader return for each batch:\n","# - a Tensor containing the matrix [n_sentences, maximum_length] containing the padded id sentences\n","# - a list containing the length of each sentence before the padding\n","# - a Tensor containing the matrix [n_sentences, maximum_length] containing the padded id sentences for the target\n","# - a list containing the length of each sentence before the padding in the targets\n","\n","train_loader = data.DataLoader(train_dataset, batch_size = BATCH_SIZE, collate_fn = collate_fn, shuffle = True, drop_last = True)\n","test_loader = data.DataLoader(test_dataset, batch_size = BATCH_SIZE, collate_fn = collate_fn, drop_last = True)\n","valid_loader = data.DataLoader(valid_dataset, batch_size = BATCH_SIZE, collate_fn = collate_fn, drop_last = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-6gEPaMyE7S"},"outputs":[],"source":["\"\"\"\n","Function that given a list of sentences expressed in word ids, converts them into actual words.\n",":param e_sentences: encoded sentences with word ids\n",":param corpus: corpus from which the mapping is done\n",":return d_sents: list containing the lists of words (each list is a sentence)\n","\"\"\"\n","def decoder(e_sentences, corpus):\n","  d_sents = [] # list containing the lists of words (each list is a sentence)\n","  for sentence in e_sentences:\n","    sent = [] # list containing the words of the current sentence\n","    for word_id in sentence:\n","      if word_id in corpus.id2word:\n","        sent.append(corpus.id2word[word_id])\n","      else:\n","        sent.append(\"<unk>\")\n","\n","    d_sents.append(sent)\n","  \n","  return d_sents"]},{"cell_type":"markdown","metadata":{"id":"wx_Vt7f5qPIs"},"source":["</br>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"O6DP4YVXrXn9"},"source":["# Model for the baseline"]},{"cell_type":"markdown","metadata":{"id":"NuKQgIenoG2W"},"source":["#### Definition of the Neural Network\n","\n","Here a **single-layer LSTM** is used. In addition, an embedding layer is used in order to convert the word ids into vector and the weights of the hidden layers are initialized at the beginning of every run of the training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aD_VjcyEtZaV"},"outputs":[],"source":["\"\"\"\n","Class that define the structure of the neural network.\n",":attribute hidden_size: the number of features in the hidden state\n",":attribute embedding_dim: the size of each embedding vector\n",":attribute num_embeddings: size of the dictionary of embeddings\n",":attribute num_layers: number of recurrent layers. Default: 1\n",":attribute padding_idx: when the input is equal to the specified value its embedding will\n","                        be a sequence of zeros of 'embedding_dim' length\n","\"\"\"\n","class Network(nn.Module):\n","  def __init__(self, hidden_size, embedding_dim, num_embeddings, num_layers = 1, padding_idx = 0):\n","    super(Network, self).__init__()\n","    self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx = padding_idx)\n","    self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers)\n","    self.linear = nn.Linear(hidden_size, num_embeddings)\n","\n","  \"\"\"\n","  Function that specify how to do a forward pass in the network.\n","  :param sents_ids: Tensor [batch_size, maximum_length] containing the sentences of the batch with word ids\n","  :param sent_lengths: length of each word in the batch before the padding\n","  \"\"\"\n","  def forward(self, sents_ids, sent_lengths):\n","    embed = self.embedding(sents_ids) # Tensor [batch_size, maximum_length, embedding_dim]\n","    embed = embed.permute(1, 0, 2) # Tensor [maximum_length, batch_size, embedding_dim]\n","\n","    # Pack the input in order to remove from the computation the padding embeddings\n","    packed_input = pack_padded_sequence(embed, sent_lengths.cpu().numpy())\n","\n","    # Pass the input into the lstms. Each will return the packed output features,\n","    # a tensor containing the final hidden state for each element in the sequence and\n","    # a tensor containing the final cell state for each element in the sequence\n","    packed_output, (h_n1, cell1) = self.lstm(packed_input)\n","\n","    output, input_sizes = pad_packed_sequence(packed_output)\n","\n","    # Decode hidden states of all time steps\n","    output = self.linear(output)\n","    output = output.permute(1, 2, 0)\n","    \n","    return output, input_sizes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nt-N7H6QHJWo"},"outputs":[],"source":["\"\"\"\n","Function to randomly initialize the weights of the RNN. It is applied recursively \n","  to every submodule.\n",":param module: current submodule of the network\n","\n","Note: In the network we used\n","      for name, param in net.named_parameters():\n","        print(name)\n","\n","      return:\n","        embedding.weight\n","        rnn.weight_ih_l0\n","        rnn.weight_hh_l0\n","        rnn.bias_ih_l0\n","        rnn.bias_hh_l0\n","\"\"\"\n","def init_weights(module):\n","  for m in module.modules():\n","    if type(m) in [nn.GRU, nn.LSTM, nn.RNN]:\n","      for name, param in m.named_parameters():\n","        if 'weight_ih' in name:\n","          for idx in range(4):\n","            mul = param.shape[0]//4\n","            torch.nn.init.xavier_uniform_(param[idx*mul:(idx+1)*mul])\n","        elif 'weight_hh' in name:\n","          for idx in range(4):\n","            mul = param.shape[0]//4\n","            torch.nn.init.orthogonal_(param[idx*mul:(idx+1)*mul])\n","        elif 'bias' in name:\n","          param.data.fill_(0)\n","    else:\n","      if type(m) in [nn.Linear]:\n","        torch.nn.init.uniform_(m.weight, -0.01, 0.01)\n","        if m.bias != None:\n","            m.bias.data.fill_(0.01)"]},{"cell_type":"markdown","metadata":{"id":"oYXN5Rm2Mper"},"source":["#### Implementation of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r7bayJrKN2xS"},"outputs":[],"source":["# Training step\n","\"\"\"\n","Function that defines the training procedure.\n",":param net: network to train\n",":param data_loader: dataloader for the training procedure\n",":param optimizer: optimizer used to update the parameters\n",":param cost_function: cost function for the loss computation\n",":return loss_array: training loss for each batch in the dataloader\n","\"\"\"\n","def training_step(net, data_loader, optimizer, cost_function):\n","  loss_array = []\n","  \n","  # Set the network to training mode\n","  net.train() \n","\n","  # Iterate over the training set\n","  for idx, (sample, length, target, _ )in enumerate(data_loader):\n","    # Forward pass\n","    output, _ = net(sample, length)\n","\n","    # Loss computation\n","    loss = cost_function(output, target)\n","    loss_array.append(loss.item())\n","\n","    if idx == 0:\n","      print(\"Loss in the first batch: \", loss.item())\n","      print(\"ppl in the first batch: \", np.exp(loss.item()))\n","      \n","    # Backward pass\n","    loss.backward()\n","\n","    # Parameters update\n","    optimizer.step()\n","\n","    # Gradients reset\n","    optimizer.zero_grad()\n","\n","  print(\"\\nLoss in the last batch: \", loss_array[-1])\n","  print(\"ppl in the last batch: \", np.exp(loss_array[-1]))\n","\n","  return loss_array\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8OPsNEjrVD5e"},"outputs":[],"source":["# Test step\n","\"\"\"\n","Function that defines the test procedure.\n",":param net: network to test\n",":param data_loader: dataloader for the test procedure\n",":param cost_function: cost function for the loss computation\n",":return losses: test loss for batch in the dataloader\n","\"\"\"\n","def test_step(net, data_loader, cost_function):\n","  losses = []\n","\n","  # Set the network to evaluation mode\n","  net.eval() \n","\n","  # Disable gradient computation \n","  with torch.no_grad():\n","    # Iterate over the test set\n","    for sample, length, target, _ in data_loader:\n","      # Forward pass\n","      output, _ = net(sample, length)\n","\n","      # Loss computation\n","      loss = cost_function(output, target)\n","      losses.append(loss.item())\n","\n","  return losses"]},{"cell_type":"markdown","metadata":{"id":"_HqUxRPybXIN"},"source":["#### Training and test\n","Since we have a small corpora, to have reliable results, the model is trained and tested from scratch for several runs.\n","The results of the runs are then averaged and the standard deviation is computed.\n","\n","In the training, for each run a fixed number of epochs are executed and an early stopping technique is used. Therefore, every five epochs a test step is computed on the valid set. If the performance of the model is deteriorating, the training continue for a fixed number of steps (*PATIENCE*) and then it is interrupted."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a5b31acb04ab43029cdddc61f08294e3","3ca8190d13d34f5bb24d6d7a11bcb66c","0606d82485924d988742fde689a6292d","f64523a4ffaf4744b91c9b8a465ad2fb","91513b5abd1844b990d9673d94b61521","8d9aa58099ba4b9ea6506a85051e9ebe","6359e7ae656c4b3295f7a7cf58e4d770","7e2a2305453b4d1f927937ff59f1e2cc","4d04284e4ed74c6a87f820657f67b04d","bd229ec61fb74341a83315fcd7cb0a92","9dc006b491694ad3844c2b3301670d3d","11f601445ce246198f47891443e6fcb0","08a0ca37fccb426585a6a0346860c551","6e771058775540de8d8f4f2eb1c5ab14","0f9e0185f8284db6a1c366c5e06a776a","5cd8f2f603794cfcb31dff32452eb1ff","22c8bdfda0454fab9ab98c36d1b4ce91","c1162c688a4e469f8d65cfc897c30f23","d5fcf47f36f04ad9ab7e984a0c969aef","f44b93323ecf482d82111ccb4127e407","c85e26f597b54ec2898fae965437454a","a4cb053ed3884127b1bbce232ba42d78","67cefc0bd22c4e43acef97fd01391938","380d60f2e2184d17b4b57021f0f1e6f8","c8f1fdaf425b4bf9b8420a8be9da04c9","9dc242920f4048c884a1d378843bacbf","73f9007c1ca24eba8df6f7f69a8a0d95","2261b9b335614e2da9bd4da8ffafa72a","272c62cf12634d7d8994e14bec74ea50","092e712fe1034f35bd51a33304afc334","2ef7373be9e1424cbb9c8cbf22334d16","cb7d2f4880a34de3bedca81f4de903fc","35d8c8b1570a4fafba78a7eea3317e03","9567402147654078ac9c8a20952b500f","21a6b1750bc64d49847c4c8b0bbc7dfe","868ffa7675d347099a8598118ebe3905","b069805e2ad0417a96abeea579de7377","170d8020172b403796299a40b63831e8","36caec4fb8594d46997583f99cf51089","674320d146d3469eb3a3930b61731670","da293482dc174e74814740f828895e33","9b4a2c20220b4f3fbd6028d2bfc4f651","f1fee3616a8f44b5aac60f3863fd6555","93a578320f4d4888a1abaa409373887a","f359a0382adf4b2994bac365d322151d","37b61158bf8542f389d12ab54434229f","918f823c1aaf4e8d9ec7667ade950a90","663cd2a1a8de447e89f5a647005e07c9","4478103761464fde8aeab390f76b893d","bba69bb31b164245b94e400df89ad38b","202d4c0735f7453d86c386f2d76bff72","4f688c1bb9bb44099891f9e660c19662","4ee15f5f7e6f482eaec01c6504f2658e","8caf0ecf431d48b586e4aa5234d9f25d","64e6ad8513d446c5bdc8cd9dba310029","155ee9bb763c4193b3291a938fe1992a","fbd3a0483bbe43a689d80f27a2d71a23","a1ada44b7f0c4cb1b288df3b3f71960d","6bf57a0fabde4281a6ddefe1cefa5834","56730a83d32c4fee9c016c096fd9ccd7","860d999cfef0419ba2deb61692c739a9","77c419015c8a4ba58a151a1a9977145b","743e5d7df44044b194f68ffa28e0c695","5e6133fc324849dc8d282b18dcf0c9b8","8ed832030b5943b3a1b9d9696689dba8","aa80dc3625f24689bdea7f1947af3708"]},"id":"uV_2GMNfcRho","executionInfo":{"status":"ok","timestamp":1658282904278,"user_tz":-120,"elapsed":3874491,"user":{"displayName":"coco lablab","userId":"08575837344437506719"}},"outputId":"9b00a03d-29aa-49a2-d9e2-b74c632a19b8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Run:   0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5b31acb04ab43029cdddc61f08294e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11f601445ce246198f47891443e6fcb0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Epoch  0\n","\n","--------- TRAIN --------\n","Loss in the first batch:  9.210811614990234\n","ppl in the first batch:  10004.713540664843\n","\n","Loss in the last batch:  6.596127986907959\n","ppl in the last batch:  732.2543943919708\n","\n","Average test loss along batches:  7.109997042419341\n","Averge test ppl along batches:  1224.143925581985\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.622444556309627\n","Average validation ppl along batches: :  751.7806227397086\n","\n","\n","Epoch  1\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.653218746185303\n","ppl in the first batch:  775.275729582685\n","\n","Loss in the last batch:  6.6288251876831055\n","ppl in the last batch:  756.5927937856459\n","\n","Average test loss along batches:  6.57081218905282\n","Averge test ppl along batches:  713.9494696613702\n","\n","\n","Epoch  2\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.570376396179199\n","ppl in the first batch:  713.6384033555294\n","\n","Loss in the last batch:  6.351897239685059\n","ppl in the last batch:  573.5798959015605\n","\n","Average test loss along batches:  6.427159250599065\n","Averge test ppl along batches:  618.4146892311655\n","\n","\n","Epoch  3\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.360428810119629\n","ppl in the first batch:  578.4943674540125\n","\n","Loss in the last batch:  6.14514684677124\n","ppl in the last batch:  466.44814043747056\n","\n","Average test loss along batches:  6.278523014742127\n","Averge test ppl along batches:  533.000847777833\n","\n","\n","Epoch  4\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.284607410430908\n","ppl in the first batch:  536.2537216890951\n","\n","Loss in the last batch:  6.127337455749512\n","ppl in the last batch:  458.21451863155494\n","\n","Average test loss along batches:  6.153896660565241\n","Averge test ppl along batches:  470.54738246018246\n","\n","\n","Epoch  5\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.931711196899414\n","ppl in the first batch:  376.7987393036163\n","\n","Loss in the last batch:  6.004522800445557\n","ppl in the last batch:  405.2575538614159\n","\n","Average test loss along batches:  6.042010119335111\n","Averge test ppl along batches:  420.73791886910834\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.006349150951092\n","Average validation ppl along batches: :  405.99837249110186\n","\n","\n","Epoch  6\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.9374542236328125\n","ppl in the first batch:  378.9689303041831\n","\n","Loss in the last batch:  5.989251613616943\n","ppl in the last batch:  399.1158052964512\n","\n","Average test loss along batches:  5.943552983224483\n","Averge test ppl along batches:  381.2872329021815\n","\n","\n","Epoch  7\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.732157230377197\n","ppl in the first batch:  308.6343461434584\n","\n","Loss in the last batch:  5.819692611694336\n","ppl in the last batch:  336.86848827965406\n","\n","Average test loss along batches:  5.854483617495184\n","Averge test ppl along batches:  348.79474204020414\n","\n","\n","Epoch  8\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.582745552062988\n","ppl in the first batch:  265.8003736576082\n","\n","Loss in the last batch:  5.748611927032471\n","ppl in the last batch:  313.75484326638883\n","\n","Average test loss along batches:  5.7759007689071025\n","Averge test ppl along batches:  322.43474313963725\n","\n","\n","Epoch  9\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.750198841094971\n","ppl in the first batch:  314.25314051222745\n","\n","Loss in the last batch:  5.718330383300781\n","ppl in the last batch:  304.3962733489656\n","\n","Average test loss along batches:  5.707537484858497\n","Averge test ppl along batches:  301.12862072571994\n","\n","\n","Epoch  10\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.564119815826416\n","ppl in the first batch:  260.8954665584734\n","\n","Loss in the last batch:  5.702077388763428\n","ppl in the last batch:  299.48891008209756\n","\n","Average test loss along batches:  5.646679336803326\n","Averge test ppl along batches:  283.3489952958655\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.66996157169342\n","Average validation ppl along batches: :  290.02338906987774\n","\n","\n","Epoch  11\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.59165096282959\n","ppl in the first batch:  268.1780063514156\n","\n","Loss in the last batch:  5.510799884796143\n","ppl in the last batch:  247.34889858318405\n","\n","Average test loss along batches:  5.592098487929485\n","Averge test ppl along batches:  268.29804959967765\n","\n","\n","Epoch  12\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.562800407409668\n","ppl in the first batch:  260.551465872609\n","\n","Loss in the last batch:  5.368659019470215\n","ppl in the last batch:  214.57493388214237\n","\n","Average test loss along batches:  5.542474282930975\n","Averge test ppl along batches:  255.30892510791105\n","\n","\n","Epoch  13\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.22005033493042\n","ppl in the first batch:  184.94349295424993\n","\n","Loss in the last batch:  5.552890300750732\n","ppl in the last batch:  257.9821253031356\n","\n","Average test loss along batches:  5.497101808428946\n","Averge test ppl along batches:  243.98379482327599\n","\n","\n","Epoch  14\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.397109508514404\n","ppl in the first batch:  220.76736687155494\n","\n","Loss in the last batch:  5.505519390106201\n","ppl in the last batch:  246.04621646760648\n","\n","Average test loss along batches:  5.455394853014198\n","Averge test ppl along batches:  234.01725524779314\n","\n","\n","Epoch  15\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.288924217224121\n","ppl in the first batch:  198.13016569974542\n","\n","Loss in the last batch:  5.469520568847656\n","ppl in the last batch:  237.34637423356958\n","\n","Average test loss along batches:  5.41554505494813\n","Averge test ppl along batches:  224.87508155710256\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.490893538181599\n","Average validation ppl along batches: :  242.47376966120697\n","\n","\n","Epoch  16\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.403541564941406\n","ppl in the first batch:  222.19193156140432\n","\n","Loss in the last batch:  5.380031108856201\n","ppl in the last batch:  217.02902684472005\n","\n","Average test loss along batches:  5.379495823945811\n","Averge test ppl along batches:  216.91288556864276\n","\n","\n","Epoch  17\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.4048919677734375\n","ppl in the first batch:  222.4921828595131\n","\n","Loss in the last batch:  5.3629374504089355\n","ppl in the last batch:  213.3507340905935\n","\n","Average test loss along batches:  5.345584907125302\n","Averge test ppl along batches:  209.68049235231445\n","\n","\n","Epoch  18\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.149600505828857\n","ppl in the first batch:  172.36261869937212\n","\n","Loss in the last batch:  5.3713507652282715\n","ppl in the last batch:  215.15329309898098\n","\n","Average test loss along batches:  5.312816505925659\n","Averge test ppl along batches:  202.92095235189217\n","\n","\n","Epoch  19\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.244910717010498\n","ppl in the first batch:  189.59888651841337\n","\n","Loss in the last batch:  5.5274176597595215\n","ppl in the last batch:  251.49362964094172\n","\n","Average test loss along batches:  5.281568845113118\n","Averge test ppl along batches:  196.6781910576644\n","\n","\n","Epoch  20\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.101494789123535\n","ppl in the first batch:  164.2672687991191\n","\n","Loss in the last batch:  5.34774112701416\n","ppl in the last batch:  210.13309738285704\n","\n","Average test loss along batches:  5.252597557718169\n","Averge test ppl along batches:  191.06191880158232\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.3733810278085565\n","Average validation ppl along batches: :  215.59055450652366\n","\n","\n","Epoch  21\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.252230644226074\n","ppl in the first batch:  190.99182846507986\n","\n","Loss in the last batch:  5.116504669189453\n","ppl in the last batch:  166.7514981543828\n","\n","Average test loss along batches:  5.22399080688732\n","Averge test ppl along batches:  185.67369532799543\n","\n","\n","Epoch  22\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.255947589874268\n","ppl in the first batch:  191.70305568835911\n","\n","Loss in the last batch:  5.172967910766602\n","ppl in the last batch:  176.43771256371667\n","\n","Average test loss along batches:  5.196193102832254\n","Averge test ppl along batches:  180.58346896661766\n","\n","\n","Epoch  23\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.226719856262207\n","ppl in the first batch:  186.18110006153174\n","\n","Loss in the last batch:  5.014002323150635\n","ppl in the last batch:  150.50590557960015\n","\n","Average test loss along batches:  5.170421325997131\n","Averge test ppl along batches:  175.98897059438505\n","\n","\n","Epoch  24\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.903996467590332\n","ppl in the first batch:  134.82753828882966\n","\n","Loss in the last batch:  5.257283687591553\n","ppl in the last batch:  191.9593608897294\n","\n","Average test loss along batches:  5.144518976342188\n","Averge test ppl along batches:  171.48897457417476\n","\n","\n","Epoch  25\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.05659294128418\n","ppl in the first batch:  157.0545098025401\n","\n","Loss in the last batch:  5.230648517608643\n","ppl in the last batch:  186.91398123111128\n","\n","Average test loss along batches:  5.120863095084645\n","Averge test ppl along batches:  167.47985830087643\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.286929048024691\n","Average validation ppl along batches: :  197.7352565819187\n","\n","\n","Epoch  26\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.013747692108154\n","ppl in the first batch:  150.46758698272214\n","\n","Loss in the last batch:  5.104125022888184\n","ppl in the last batch:  164.69989882557687\n","\n","Average test loss along batches:  5.097689172085743\n","Averge test ppl along batches:  163.64331849322434\n","\n","\n","Epoch  27\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.1165852546691895\n","ppl in the first batch:  166.7649364453166\n","\n","Loss in the last batch:  5.0769429206848145\n","ppl in the last batch:  160.28330739859985\n","\n","Average test loss along batches:  5.0751396481123505\n","Averge test ppl along batches:  159.9945333539541\n","\n","\n","Epoch  28\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.080996036529541\n","ppl in the first batch:  160.93427253886713\n","\n","Loss in the last batch:  5.029328346252441\n","ppl in the last batch:  152.83032915226585\n","\n","Average test loss along batches:  5.052763406907405\n","Averge test ppl along batches:  156.45421431794867\n","\n","\n","Epoch  29\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.947338104248047\n","ppl in the first batch:  140.79967060217928\n","\n","Loss in the last batch:  5.158658981323242\n","ppl in the last batch:  173.9310543500158\n","\n","Average test loss along batches:  5.031287093866543\n","Averge test ppl along batches:  153.1299785678389\n","\n","--------- TEST --------\n","Average test loss along batches:  5.175630828429913\n","Average test ppl along batches:  176.90817779204932\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67cefc0bd22c4e43acef97fd01391938"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Epoch  0\n","\n","--------- TRAIN --------\n","Loss in the first batch:  9.210820198059082\n","ppl in the first batch:  10004.799412178483\n","\n","Loss in the last batch:  6.700233459472656\n","ppl in the last batch:  812.5955111442021\n","\n","Average test loss along batches:  7.10125282148248\n","Averge test ppl along batches:  1213.4864044054127\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.62128210067749\n","Average validation ppl along batches: :  750.907218865653\n","\n","\n","Epoch  1\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.658405780792236\n","ppl in the first batch:  779.3075592020244\n","\n","Loss in the last batch:  6.628448486328125\n","ppl in the last batch:  756.3078379300565\n","\n","Average test loss along batches:  6.568559224202753\n","Averge test ppl along batches:  712.3427771919394\n","\n","\n","Epoch  2\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.435847759246826\n","ppl in the first batch:  623.8112004751666\n","\n","Loss in the last batch:  6.2878875732421875\n","ppl in the last batch:  538.0156092636922\n","\n","Average test loss along batches:  6.430312668351823\n","Averge test ppl along batches:  620.3678870966083\n","\n","\n","Epoch  3\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.396198272705078\n","ppl in the first batch:  599.5613309303563\n","\n","Loss in the last batch:  6.438724040985107\n","ppl in the last batch:  625.6080401089708\n","\n","Average test loss along batches:  6.285675130841213\n","Averge test ppl along batches:  536.8265965134913\n","\n","\n","Epoch  4\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.100348949432373\n","ppl in the first batch:  446.0133790465572\n","\n","Loss in the last batch:  6.293859481811523\n","ppl in the last batch:  541.2382022289048\n","\n","Average test loss along batches:  6.15957726082301\n","Averge test ppl along batches:  473.22798053694436\n","\n","\n","Epoch  5\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.269379615783691\n","ppl in the first batch:  528.1496205320302\n","\n","Loss in the last batch:  5.963740348815918\n","ppl in the last batch:  389.0626360640471\n","\n","Average test loss along batches:  6.0492613863545825\n","Averge test ppl along batches:  423.7998900325529\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.017692620937641\n","Average validation ppl along batches: :  410.6300226720237\n","\n","\n","Epoch  6\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.962088584899902\n","ppl in the first batch:  388.4205268930961\n","\n","Loss in the last batch:  5.749032497406006\n","ppl in the last batch:  313.88682701030064\n","\n","Average test loss along batches:  5.9524540872152905\n","Averge test ppl along batches:  384.69625975590606\n","\n","\n","Epoch  7\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.031479358673096\n","ppl in the first batch:  416.33047613724386\n","\n","Loss in the last batch:  5.653237342834473\n","ppl in the last batch:  285.21330611513474\n","\n","Average test loss along batches:  5.867297954210952\n","Averge test ppl along batches:  353.2930753334021\n","\n","\n","Epoch  8\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.686127662658691\n","ppl in the first batch:  294.7500363253492\n","\n","Loss in the last batch:  5.781634330749512\n","ppl in the last batch:  324.2887526396172\n","\n","Average test loss along batches:  5.789948027972217\n","Averge test ppl along batches:  326.9960292876213\n","\n","\n","Epoch  9\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.823347091674805\n","ppl in the first batch:  338.1018196458987\n","\n","Loss in the last batch:  5.519562244415283\n","ppl in the last batch:  249.5257819733083\n","\n","Average test loss along batches:  5.719329893498298\n","Averge test ppl along batches:  304.7006726280139\n","\n","\n","Epoch  10\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.817368030548096\n","ppl in the first batch:  336.0863196025323\n","\n","Loss in the last batch:  5.62114953994751\n","ppl in the last batch:  276.20671145769467\n","\n","Average test loss along batches:  5.656165820459979\n","Averge test ppl along batches:  286.04977108727496\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.6810127680118265\n","Average validation ppl along batches: :  293.2462700239662\n","\n","\n","Epoch  11\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.599475383758545\n","ppl in the first batch:  270.28457454786724\n","\n","Loss in the last batch:  5.409655570983887\n","ppl in the last batch:  223.55457573616482\n","\n","Average test loss along batches:  5.598287509819507\n","Averge test ppl along batches:  269.96370116193475\n","\n","\n","Epoch  12\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.451780796051025\n","ppl in the first batch:  233.17303001490032\n","\n","Loss in the last batch:  5.437161922454834\n","ppl in the last batch:  229.78909786644985\n","\n","Average test loss along batches:  5.547035199866447\n","Averge test ppl along batches:  256.47602741338056\n","\n","\n","Epoch  13\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.443385124206543\n","ppl in the first batch:  231.22358069125008\n","\n","Loss in the last batch:  5.325266361236572\n","ppl in the last batch:  205.46308057701367\n","\n","Average test loss along batches:  5.499621757089275\n","Averge test ppl along batches:  244.5993967770791\n","\n","\n","Epoch  14\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.465945243835449\n","ppl in the first batch:  236.4992989922076\n","\n","Loss in the last batch:  5.518597602844238\n","ppl in the last batch:  249.28519508968023\n","\n","Average test loss along batches:  5.455510924758795\n","Averge test ppl along batches:  234.04441961535287\n","\n","\n","Epoch  15\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.374678611755371\n","ppl in the first batch:  215.87048292517048\n","\n","Loss in the last batch:  5.649183750152588\n","ppl in the last batch:  284.05950763911676\n","\n","Average test loss along batches:  5.415042241414388\n","Averge test ppl along batches:  224.76203974455242\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.492083320250878\n","Average validation ppl along batches: :  242.76243229338033\n","\n","\n","Epoch  16\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.5461812019348145\n","ppl in the first batch:  256.25709091542046\n","\n","Loss in the last batch:  5.3396992683410645\n","ppl in the last batch:  208.4500133437726\n","\n","Average test loss along batches:  5.376883091629005\n","Averge test ppl along batches:  216.34688998204075\n","\n","\n","Epoch  17\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.408375263214111\n","ppl in the first batch:  223.2685402216989\n","\n","Loss in the last batch:  5.498985767364502\n","ppl in the last batch:  244.4438835316981\n","\n","Average test loss along batches:  5.3414718281007065\n","Averge test ppl along batches:  208.81983111454244\n","\n","\n","Epoch  18\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.30342435836792\n","ppl in the first batch:  201.02401094610659\n","\n","Loss in the last batch:  5.472836017608643\n","ppl in the last batch:  238.13458989825273\n","\n","Average test loss along batches:  5.308149220192269\n","Averge test ppl along batches:  201.97606902146077\n","\n","\n","Epoch  19\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.284236907958984\n","ppl in the first batch:  197.20364148749798\n","\n","Loss in the last batch:  5.534880638122559\n","ppl in the last batch:  253.37754221290965\n","\n","Average test loss along batches:  5.275445946093926\n","Averge test ppl along batches:  195.47762956367907\n","\n","\n","Epoch  20\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.24425745010376\n","ppl in the first batch:  189.47506828787604\n","\n","Loss in the last batch:  5.119773864746094\n","ppl in the last batch:  167.29753347301204\n","\n","Average test loss along batches:  5.2446580825875335\n","Averge test ppl along batches:  189.55099336310764\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.372678655844468\n","Average validation ppl along batches: :  215.43918291112138\n","\n","\n","Epoch  21\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.229051113128662\n","ppl in the first batch:  186.61564234749562\n","\n","Loss in the last batch:  5.333181858062744\n","ppl in the last batch:  207.09587660988487\n","\n","Average test loss along batches:  5.215248610875378\n","Averge test ppl along batches:  184.05757400665456\n","\n","\n","Epoch  22\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.222350120544434\n","ppl in the first batch:  185.36931279824668\n","\n","Loss in the last batch:  5.0261616706848145\n","ppl in the last batch:  152.34713055333197\n","\n","Average test loss along batches:  5.187685488928762\n","Averge test ppl along batches:  179.05365131154701\n","\n","\n","Epoch  23\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.249569416046143\n","ppl in the first batch:  190.4842313444852\n","\n","Loss in the last batch:  5.214948654174805\n","ppl in the last batch:  184.00237298341236\n","\n","Average test loss along batches:  5.161085708682033\n","Averge test ppl along batches:  174.35365015315986\n","\n","\n","Epoch  24\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.1918230056762695\n","ppl in the first batch:  179.79602352221997\n","\n","Loss in the last batch:  5.125593662261963\n","ppl in the last batch:  168.27400993426428\n","\n","Average test loss along batches:  5.1355324234229425\n","Averge test ppl along batches:  169.95478369769864\n","\n","\n","Epoch  25\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.121932506561279\n","ppl in the first batch:  167.65905898600468\n","\n","Loss in the last batch:  5.1789631843566895\n","ppl in the last batch:  177.4986821457086\n","\n","Average test loss along batches:  5.110886941035951\n","Averge test ppl along batches:  165.81735989266272\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.286791159556462\n","Average validation ppl along batches: :  197.7079930499804\n","\n","\n","Epoch  26\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.200691223144531\n","ppl in the first batch:  181.39758475915693\n","\n","Loss in the last batch:  5.152569770812988\n","ppl in the last batch:  172.87516956073506\n","\n","Average test loss along batches:  5.087597908676124\n","Averge test ppl along batches:  162.00025489808644\n","\n","\n","Epoch  27\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.161981105804443\n","ppl in the first batch:  174.50983582345364\n","\n","Loss in the last batch:  5.416056156158447\n","ppl in the last batch:  224.99004485989553\n","\n","Average test loss along batches:  5.064665015611111\n","Averge test ppl along batches:  158.32739598338375\n","\n","\n","Epoch  28\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.995137691497803\n","ppl in the first batch:  147.6932800924337\n","\n","Loss in the last batch:  4.8734917640686035\n","ppl in the last batch:  130.77676218040247\n","\n","Average test loss along batches:  5.0426456721406\n","Averge test ppl along batches:  154.87923313097673\n","\n","\n","Epoch  29\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.322717189788818\n","ppl in the first batch:  204.9399869693509\n","\n","Loss in the last batch:  5.074086666107178\n","ppl in the last batch:  159.8261506569395\n","\n","Average test loss along batches:  5.022008151949994\n","Averge test ppl along batches:  151.71566619971435\n","\n","--------- TEST --------\n","Average test loss along batches:  5.169229647208905\n","Average test ppl along batches:  175.77937318236505\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9567402147654078ac9c8a20952b500f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Epoch  0\n","\n","--------- TRAIN --------\n","Loss in the first batch:  9.210582733154297\n","ppl in the first batch:  10002.423905499572\n","\n","Loss in the last batch:  6.611626148223877\n","ppl in the last batch:  743.6913883865839\n","\n","Average test loss along batches:  7.105494102930914\n","Averge test ppl along batches:  1218.6440716079137\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.61511153441209\n","Average validation ppl along batches: :  746.2879624831261\n","\n","\n","Epoch  1\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.575214862823486\n","ppl in the first batch:  717.0996858636265\n","\n","Loss in the last batch:  6.673388957977295\n","ppl in the last batch:  791.0719765303562\n","\n","Average test loss along batches:  6.559817826548305\n","Averge test ppl along batches:  706.1430423617937\n","\n","\n","Epoch  2\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.486054420471191\n","ppl in the first batch:  655.9302259927223\n","\n","Loss in the last batch:  6.350910186767578\n","ppl in the last batch:  573.0140215118294\n","\n","Average test loss along batches:  6.413959066980325\n","Averge test ppl along batches:  610.3051432821252\n","\n","\n","Epoch  3\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.33974552154541\n","ppl in the first batch:  566.6520922833132\n","\n","Loss in the last batch:  6.245090961456299\n","ppl in the last batch:  515.4761112521614\n","\n","Average test loss along batches:  6.261110465457632\n","Averge test ppl along batches:  523.8002793866244\n","\n","\n","Epoch  4\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.19581413269043\n","ppl in the first batch:  490.69076982086847\n","\n","Loss in the last batch:  6.086666107177734\n","ppl in the last batch:  439.95220991230843\n","\n","Average test loss along batches:  6.130417139381397\n","Averge test ppl along batches:  459.6278495735052\n","\n","\n","Epoch  5\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.950978755950928\n","ppl in the first batch:  384.1291237961801\n","\n","Loss in the last batch:  6.114048957824707\n","ppl in the last batch:  452.1658140592141\n","\n","Average test loss along batches:  6.018990935437393\n","Averge test ppl along batches:  411.1634958175161\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.987246513366699\n","Average validation ppl along batches: :  398.3163398673902\n","\n","\n","Epoch  6\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.865499496459961\n","ppl in the first batch:  352.6582636757759\n","\n","Loss in the last batch:  5.8187360763549805\n","ppl in the last batch:  336.54641572734533\n","\n","Average test loss along batches:  5.922237584217135\n","Averge test ppl along batches:  373.24594943752084\n","\n","\n","Epoch  7\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.725809574127197\n","ppl in the first batch:  306.68144613347647\n","\n","Loss in the last batch:  5.865536212921143\n","ppl in the last batch:  352.6712122769365\n","\n","Average test loss along batches:  5.836460467705806\n","Averge test ppl along batches:  342.5646735315205\n","\n","\n","Epoch  8\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.9430108070373535\n","ppl in the first batch:  381.0805640745666\n","\n","Loss in the last batch:  5.6805009841918945\n","ppl in the last batch:  293.09622972508606\n","\n","Average test loss along batches:  5.761177149356047\n","Averge test ppl along batches:  317.7221152568904\n","\n","\n","Epoch  9\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.7029500007629395\n","ppl in the first batch:  299.7503617550992\n","\n","Loss in the last batch:  5.5864176750183105\n","ppl in the last batch:  266.7782195976989\n","\n","Average test loss along batches:  5.693137066549362\n","Averge test ppl along batches:  296.823316115811\n","\n","\n","Epoch  10\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.558494567871094\n","ppl in the first batch:  259.4319849512494\n","\n","Loss in the last batch:  5.693365097045898\n","ppl in the last batch:  296.8910086016508\n","\n","Average test loss along batches:  5.6323839075852025\n","Averge test ppl along batches:  279.32721481910755\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.658407037074749\n","Average validation ppl along batches: :  286.69158954532566\n","\n","\n","Epoch  11\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.439034461975098\n","ppl in the first batch:  230.21979015184482\n","\n","Loss in the last batch:  5.468389987945557\n","ppl in the last batch:  237.07818658816032\n","\n","Average test loss along batches:  5.577896195822474\n","Averge test ppl along batches:  264.51453322588657\n","\n","\n","Epoch  12\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.617879867553711\n","ppl in the first batch:  275.3050808199217\n","\n","Loss in the last batch:  5.570855617523193\n","ppl in the last batch:  262.65873854322984\n","\n","Average test loss along batches:  5.52860885196262\n","Averge test ppl along batches:  251.79338538960963\n","\n","\n","Epoch  13\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.575362682342529\n","ppl in the first batch:  263.8452302923238\n","\n","Loss in the last batch:  5.447865009307861\n","ppl in the last batch:  232.26175949002987\n","\n","Average test loss along batches:  5.483533292419108\n","Averge test ppl along batches:  240.69565483378108\n","\n","\n","Epoch  14\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.523770809173584\n","ppl in the first batch:  250.57814029139197\n","\n","Loss in the last batch:  5.287456512451172\n","ppl in the last batch:  197.83958240728884\n","\n","Average test loss along batches:  5.4412308276334675\n","Averge test ppl along batches:  230.7259926922551\n","\n","\n","Epoch  15\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.490396976470947\n","ppl in the first batch:  242.35339636021547\n","\n","Loss in the last batch:  5.3732008934021\n","ppl in the last batch:  215.55172272752466\n","\n","Average test loss along batches:  5.402560152056736\n","Averge test ppl along batches:  221.97397650634392\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.47948774924645\n","Average validation ppl along batches: :  239.72387718028202\n","\n","\n","Epoch  16\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.420232772827148\n","ppl in the first batch:  225.93170714387233\n","\n","Loss in the last batch:  5.599181652069092\n","ppl in the last batch:  270.20519506185815\n","\n","Average test loss along batches:  5.365677546148431\n","Averge test ppl along batches:  213.9361371920923\n","\n","\n","Epoch  17\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.254990100860596\n","ppl in the first batch:  191.51958996587356\n","\n","Loss in the last batch:  5.122093677520752\n","ppl in the last batch:  167.68608293508515\n","\n","Average test loss along batches:  5.331498879820244\n","Averge test ppl along batches:  206.74763188178702\n","\n","\n","Epoch  18\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.368260383605957\n","ppl in the first batch:  214.48941366477158\n","\n","Loss in the last batch:  5.431509017944336\n","ppl in the last batch:  228.49378662338114\n","\n","Average test loss along batches:  5.299029239962271\n","Averge test ppl along batches:  200.1424253712499\n","\n","\n","Epoch  19\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.2684807777404785\n","ppl in the first batch:  194.12082563361204\n","\n","Loss in the last batch:  5.257742881774902\n","ppl in the last batch:  192.04752775299562\n","\n","Average test loss along batches:  5.267877382774875\n","Averge test ppl along batches:  194.00372943588684\n","\n","\n","Epoch  20\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.201414108276367\n","ppl in the first batch:  181.52876178337814\n","\n","Loss in the last batch:  5.205780029296875\n","ppl in the last batch:  182.32303462486885\n","\n","Average test loss along batches:  5.2378510739342445\n","Averge test ppl along batches:  188.26509962115247\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.36461615562439\n","Average validation ppl along batches: :  213.7091878655647\n","\n","\n","Epoch  21\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.1417622566223145\n","ppl in the first batch:  171.01687855340487\n","\n","Loss in the last batch:  5.175624847412109\n","ppl in the last batch:  176.90711970425255\n","\n","Average test loss along batches:  5.209464402685064\n","Averge test ppl along batches:  182.99601976467213\n","\n","\n","Epoch  22\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.205864429473877\n","ppl in the first batch:  182.33842337066002\n","\n","Loss in the last batch:  5.275311470031738\n","ppl in the last batch:  195.45134426922056\n","\n","Average test loss along batches:  5.182111333675762\n","Averge test ppl along batches:  178.05835500567252\n","\n","\n","Epoch  23\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.952775001525879\n","ppl in the first batch:  141.5672687332509\n","\n","Loss in the last batch:  5.3184099197387695\n","ppl in the last batch:  204.05915345713396\n","\n","Average test loss along batches:  5.155601929674773\n","Averge test ppl along batches:  173.40015004799753\n","\n","\n","Epoch  24\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.06942081451416\n","ppl in the first batch:  159.08216257600574\n","\n","Loss in the last batch:  5.165133953094482\n","ppl in the last batch:  175.0609069514801\n","\n","Average test loss along batches:  5.130664816004319\n","Averge test ppl along batches:  169.12952068936576\n","\n","\n","Epoch  25\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.051464080810547\n","ppl in the first batch:  156.25106128392235\n","\n","Loss in the last batch:  5.0770416259765625\n","ppl in the last batch:  160.29912899004353\n","\n","Average test loss along batches:  5.106234252180683\n","Averge test ppl along batches:  165.04765529679307\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.279074549674988\n","Average validation ppl along batches: :  196.18822885220186\n","\n","\n","Epoch  26\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.132190227508545\n","ppl in the first batch:  169.38770967809185\n","\n","Loss in the last batch:  5.02041482925415\n","ppl in the last batch:  151.47412666175637\n","\n","Average test loss along batches:  5.082821501988798\n","Averge test ppl along batches:  161.22832080041456\n","\n","\n","Epoch  27\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.055636882781982\n","ppl in the first batch:  156.90442825793517\n","\n","Loss in the last batch:  5.053863525390625\n","ppl in the last batch:  156.6264272008167\n","\n","Average test loss along batches:  5.060237621789291\n","Averge test ppl along batches:  157.62796771328792\n","\n","\n","Epoch  28\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.894077301025391\n","ppl in the first batch:  133.49677243422533\n","\n","Loss in the last batch:  4.932159423828125\n","ppl in the last batch:  138.67865522812752\n","\n","Average test loss along batches:  5.038762943929733\n","Averge test ppl along batches:  154.27904510073495\n","\n","\n","Epoch  29\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.0795159339904785\n","ppl in the first batch:  160.69624950616085\n","\n","Loss in the last batch:  4.983208656311035\n","ppl in the last batch:  145.94190861194187\n","\n","Average test loss along batches:  5.017280378298128\n","Averge test ppl along batches:  151.00008176398595\n","\n","--------- TEST --------\n","Average test loss along batches:  5.165808435144095\n","Average test ppl along batches:  175.17902221964408\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f359a0382adf4b2994bac365d322151d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Epoch  0\n","\n","--------- TRAIN --------\n","Loss in the first batch:  9.210858345031738\n","ppl in the first batch:  10005.181072267635\n","\n","Loss in the last batch:  6.820371627807617\n","ppl in the last batch:  916.3254788421674\n","\n","Average test loss along batches:  7.105370387276195\n","Averge test ppl along batches:  1218.4933155843576\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.624696172200716\n","Average validation ppl along batches: :  753.4752510465466\n","\n","\n","Epoch  1\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.51230525970459\n","ppl in the first batch:  673.3769384500234\n","\n","Loss in the last batch:  6.54074764251709\n","ppl in the last batch:  692.8043544479538\n","\n","Average test loss along batches:  6.577591650743644\n","Averge test ppl along batches:  718.8061068315928\n","\n","\n","Epoch  2\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.443087577819824\n","ppl in the first batch:  628.3438684389773\n","\n","Loss in the last batch:  6.412243366241455\n","ppl in the last batch:  609.2589400393347\n","\n","Average test loss along batches:  6.451813646284594\n","Averge test ppl along batches:  633.8508321821216\n","\n","\n","Epoch  3\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.4887590408325195\n","ppl in the first batch:  657.7066694572492\n","\n","Loss in the last batch:  6.3817291259765625\n","ppl in the last batch:  590.9486493961404\n","\n","Average test loss along batches:  6.314613887345591\n","Averge test ppl along batches:  552.588657921977\n","\n","\n","Epoch  4\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.325120449066162\n","ppl in the first batch:  558.4250713927096\n","\n","Loss in the last batch:  6.1568121910095215\n","ppl in the last batch:  471.9212795253686\n","\n","Average test loss along batches:  6.189444955625491\n","Averge test ppl along batches:  487.575405110072\n","\n","\n","Epoch  5\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.995424747467041\n","ppl in the first batch:  401.5872209256738\n","\n","Loss in the last batch:  6.123806953430176\n","ppl in the last batch:  456.599643548263\n","\n","Average test loss along batches:  6.076796277654407\n","Averge test ppl along batches:  435.63131492659227\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.041070681351882\n","Average validation ppl along batches: :  420.34284728881795\n","\n","\n","Epoch  6\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.971094608306885\n","ppl in the first batch:  391.9344507395403\n","\n","Loss in the last batch:  5.98740816116333\n","ppl in the last batch:  398.3807320303772\n","\n","Average test loss along batches:  5.979122841920664\n","Averge test ppl along batches:  395.09365652418535\n","\n","\n","Epoch  7\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.9145660400390625\n","ppl in the first batch:  370.3935318601868\n","\n","Loss in the last batch:  5.801013946533203\n","ppl in the last batch:  330.6346358491739\n","\n","Average test loss along batches:  5.891428951803408\n","Averge test ppl along batches:  361.9220842582776\n","\n","\n","Epoch  8\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.7833051681518555\n","ppl in the first batch:  324.83103932696855\n","\n","Loss in the last batch:  5.734035968780518\n","ppl in the last batch:  309.2147343702527\n","\n","Average test loss along batches:  5.811419402809085\n","Averge test ppl along batches:  334.09300182972754\n","\n","\n","Epoch  9\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.682410717010498\n","ppl in the first batch:  293.6565000270133\n","\n","Loss in the last batch:  5.790777206420898\n","ppl in the last batch:  327.267279789905\n","\n","Average test loss along batches:  5.739909641637468\n","Averge test ppl along batches:  311.03630498039996\n","\n","\n","Epoch  10\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.617772102355957\n","ppl in the first batch:  275.2754141119926\n","\n","Loss in the last batch:  5.714428424835205\n","ppl in the last batch:  303.21084598149594\n","\n","Average test loss along batches:  5.675616993025921\n","Averge test ppl along batches:  291.66824031069984\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.697845284755413\n","Average validation ppl along batches: :  298.22412011450143\n","\n","\n","Epoch  11\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.563580513000488\n","ppl in the first batch:  260.7548028296692\n","\n","Loss in the last batch:  5.701157569885254\n","ppl in the last batch:  299.21356118377133\n","\n","Average test loss along batches:  5.618545554725729\n","Averge test ppl along batches:  275.48840889341824\n","\n","\n","Epoch  12\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.715331077575684\n","ppl in the first batch:  303.4846636451043\n","\n","Loss in the last batch:  5.547085285186768\n","ppl in the last batch:  256.48887341906357\n","\n","Average test loss along batches:  5.565840022930453\n","Averge test ppl along batches:  261.3446470244079\n","\n","\n","Epoch  13\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.511570453643799\n","ppl in the first batch:  247.53957139276318\n","\n","Loss in the last batch:  5.3586106300354\n","ppl in the last batch:  212.4295980198578\n","\n","Average test loss along batches:  5.518062817995951\n","Averge test ppl along batches:  249.15191678522936\n","\n","\n","Epoch  14\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.64165735244751\n","ppl in the first batch:  281.9295881775826\n","\n","Loss in the last batch:  5.620694160461426\n","ppl in the last batch:  276.08096122159014\n","\n","Average test loss along batches:  5.473803697292845\n","Averge test ppl along batches:  238.3651394340635\n","\n","\n","Epoch  15\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.537636756896973\n","ppl in the first batch:  254.07684405081062\n","\n","Loss in the last batch:  5.4219889640808105\n","ppl in the last batch:  226.32883504608884\n","\n","Average test loss along batches:  5.432880709341854\n","Averge test ppl along batches:  228.8074246429886\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.5041300150064325\n","Average validation ppl along batches: :  245.70460335038663\n","\n","\n","Epoch  16\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.513273239135742\n","ppl in the first batch:  247.96143725521515\n","\n","Loss in the last batch:  5.371606349945068\n","ppl in the last batch:  215.2082900203525\n","\n","Average test loss along batches:  5.393621682032058\n","Averge test ppl along batches:  219.99870985331614\n","\n","\n","Epoch  17\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.237248420715332\n","ppl in the first batch:  188.15167523407575\n","\n","Loss in the last batch:  5.004052639007568\n","ppl in the last batch:  149.01584446863478\n","\n","Average test loss along batches:  5.3574412337176875\n","Averge test ppl along batches:  212.18132882099573\n","\n","\n","Epoch  18\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.243474006652832\n","ppl in the first batch:  189.32668341967812\n","\n","Loss in the last batch:  5.540004253387451\n","ppl in the last batch:  254.67908270506535\n","\n","Average test loss along batches:  5.323066331843082\n","Averge test ppl along batches:  205.011552629966\n","\n","\n","Epoch  19\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.348450183868408\n","ppl in the first batch:  210.2821465317764\n","\n","Loss in the last batch:  5.272778511047363\n","ppl in the last batch:  194.95690049799964\n","\n","Average test loss along batches:  5.290236950646434\n","Averge test ppl along batches:  198.39042858074382\n","\n","\n","Epoch  20\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.38722562789917\n","ppl in the first batch:  218.5960766366696\n","\n","Loss in the last batch:  5.224574089050293\n","ppl in the last batch:  185.78202707352955\n","\n","Average test loss along batches:  5.2595172603380735\n","Averge test ppl along batches:  192.38859527131183\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.380083313355079\n","Average validation ppl along batches: :  217.04035703204917\n","\n","\n","Epoch  21\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.350435733795166\n","ppl in the first batch:  210.70008701596225\n","\n","Loss in the last batch:  5.17725944519043\n","ppl in the last batch:  177.19652815785835\n","\n","Average test loss along batches:  5.229956901236756\n","Averge test ppl along batches:  186.78475315483513\n","\n","\n","Epoch  22\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.094088077545166\n","ppl in the first batch:  163.05508321350402\n","\n","Loss in the last batch:  5.3764824867248535\n","ppl in the last batch:  216.2602377147365\n","\n","Average test loss along batches:  5.201728074699414\n","Averge test ppl along batches:  181.58576466742292\n","\n","\n","Epoch  23\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.393397808074951\n","ppl in the first batch:  219.94946338428952\n","\n","Loss in the last batch:  5.105888366699219\n","ppl in the last batch:  164.99057758082185\n","\n","Average test loss along batches:  5.174484149143213\n","Averge test ppl along batches:  176.70543711041228\n","\n","\n","Epoch  24\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.105893135070801\n","ppl in the first batch:  164.99136431907903\n","\n","Loss in the last batch:  5.0246052742004395\n","ppl in the last batch:  152.11020243980292\n","\n","Average test loss along batches:  5.1486261801814015\n","Averge test ppl along batches:  172.1947631655654\n","\n","\n","Epoch  25\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.212308406829834\n","ppl in the first batch:  183.51720197424908\n","\n","Loss in the last batch:  5.318187236785889\n","ppl in the last batch:  204.01371802131604\n","\n","Average test loss along batches:  5.123809773083691\n","Averge test ppl along batches:  167.97409533569538\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.289983731049758\n","Average validation ppl along batches: :  198.34019859631087\n","\n","\n","Epoch  26\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.070394515991211\n","ppl in the first batch:  159.23713654962776\n","\n","Loss in the last batch:  5.038441181182861\n","ppl in the last batch:  154.22941183689449\n","\n","Average test loss along batches:  5.099355352886554\n","Averge test ppl along batches:  163.91620512478053\n","\n","\n","Epoch  27\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.972665309906006\n","ppl in the first batch:  144.4112756900039\n","\n","Loss in the last batch:  5.125544548034668\n","ppl in the last batch:  168.26574548924512\n","\n","Average test loss along batches:  5.07618675856104\n","Averge test ppl along batches:  160.16215304441138\n","\n","\n","Epoch  28\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.160750389099121\n","ppl in the first batch:  174.29519576091027\n","\n","Loss in the last batch:  4.95315408706665\n","ppl in the last batch:  141.6209450111818\n","\n","Average test loss along batches:  5.05348815874422\n","Averge test ppl along batches:  156.56764589706057\n","\n","\n","Epoch  29\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.839087963104248\n","ppl in the first batch:  126.35405959848578\n","\n","Loss in the last batch:  4.789541244506836\n","ppl in the last batch:  120.24619240667913\n","\n","Average test loss along batches:  5.031761850940582\n","Averge test ppl along batches:  153.2026953684534\n","\n","--------- TEST --------\n","Average test loss along batches:  5.174101056723759\n","Average test ppl along batches:  176.63775556195085\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"155ee9bb763c4193b3291a938fe1992a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Epoch  0\n","\n","--------- TRAIN --------\n","Loss in the first batch:  9.210650444030762\n","ppl in the first batch:  10003.101201318876\n","\n","Loss in the last batch:  6.539794445037842\n","ppl in the last batch:  692.1442897196765\n","\n","Average test loss along batches:  7.100901458542823\n","Averge test ppl along batches:  1213.060105152392\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.6219818867169895\n","Average validation ppl along batches: :  751.43287715709\n","\n","\n","Epoch  1\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.594475269317627\n","ppl in the first batch:  731.0451841904904\n","\n","Loss in the last batch:  6.462896347045898\n","ppl in the last batch:  640.9146822487149\n","\n","Average test loss along batches:  6.574858546438464\n","Averge test ppl along batches:  716.8442170124307\n","\n","\n","Epoch  2\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.463304042816162\n","ppl in the first batch:  641.1760337260936\n","\n","Loss in the last batch:  6.400740146636963\n","ppl in the last batch:  602.2906563439994\n","\n","Average test loss along batches:  6.448153869565037\n","Averge test ppl along batches:  631.5353193772493\n","\n","\n","Epoch  3\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.434138774871826\n","ppl in the first batch:  622.7460273219901\n","\n","Loss in the last batch:  6.175622940063477\n","ppl in the last batch:  480.88249160566113\n","\n","Average test loss along batches:  6.307925232287774\n","Averge test ppl along batches:  548.9049163721738\n","\n","\n","Epoch  4\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.163105487823486\n","ppl in the first batch:  474.90058520462856\n","\n","Loss in the last batch:  6.192615509033203\n","ppl in the last batch:  489.12374221796443\n","\n","Average test loss along batches:  6.183268375774134\n","Averge test ppl along batches:  484.5731381025412\n","\n","\n","Epoch  5\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.262767314910889\n","ppl in the first batch:  524.6688569455707\n","\n","Loss in the last batch:  5.886935234069824\n","ppl in the last batch:  360.2993573391475\n","\n","Average test loss along batches:  6.073513682755887\n","Averge test ppl along batches:  434.2036582857491\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.036955439127409\n","Average validation ppl along batches: :  418.61658907645534\n","\n","\n","Epoch  6\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.881494522094727\n","ppl in the first batch:  358.34439532612663\n","\n","Loss in the last batch:  5.9608964920043945\n","ppl in the last batch:  387.9577694222656\n","\n","Average test loss along batches:  5.976554011282492\n","Averge test ppl along batches:  394.08003030879826\n","\n","\n","Epoch  7\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.8854146003723145\n","ppl in the first batch:  359.75189034905674\n","\n","Loss in the last batch:  5.918245315551758\n","ppl in the last batch:  371.75882181079396\n","\n","Average test loss along batches:  5.888411420302486\n","Averge test ppl along batches:  360.83161905213933\n","\n","\n","Epoch  8\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.815430641174316\n","ppl in the first batch:  335.435819877359\n","\n","Loss in the last batch:  5.837960243225098\n","ppl in the last batch:  343.0788291052531\n","\n","Average test loss along batches:  5.809027401823975\n","Averge test ppl along batches:  333.2948060633467\n","\n","\n","Epoch  9\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.6782145500183105\n","ppl in the first batch:  292.42685002721635\n","\n","Loss in the last batch:  5.771991729736328\n","ppl in the last batch:  321.1767933879634\n","\n","Average test loss along batches:  5.737686419958756\n","Averge test ppl along batches:  310.3455704368153\n","\n","\n","Epoch  10\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.7736005783081055\n","ppl in the first batch:  321.6939341022965\n","\n","Loss in the last batch:  5.713970184326172\n","ppl in the last batch:  303.0719343189952\n","\n","Average test loss along batches:  5.672572546716513\n","Averge test ppl along batches:  290.7816223281496\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.691726932158837\n","Average validation ppl along batches: :  296.4050503246442\n","\n","\n","Epoch  11\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.697415828704834\n","ppl in the first batch:  298.09607345886315\n","\n","Loss in the last batch:  5.5923967361450195\n","ppl in the last batch:  268.37808094821224\n","\n","Average test loss along batches:  5.614160003545985\n","Averge test ppl along batches:  274.282885750668\n","\n","\n","Epoch  12\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.499770641326904\n","ppl in the first batch:  244.63581648288562\n","\n","Loss in the last batch:  5.71119499206543\n","ppl in the last batch:  302.23201743690544\n","\n","Average test loss along batches:  5.562340318340144\n","Averge test ppl along batches:  260.43161656390527\n","\n","\n","Epoch  13\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.797686576843262\n","ppl in the first batch:  329.53632044741636\n","\n","Loss in the last batch:  5.496918678283691\n","ppl in the last batch:  243.93911812644012\n","\n","Average test loss along batches:  5.514539004460862\n","Averge test ppl along batches:  248.27549696547408\n","\n","\n","Epoch  14\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.495100021362305\n","ppl in the first batch:  243.4958797323172\n","\n","Loss in the last batch:  5.518629550933838\n","ppl in the last batch:  249.29315940265045\n","\n","Average test loss along batches:  5.471502629226383\n","Averge test ppl along batches:  237.81727560128022\n","\n","\n","Epoch  15\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.35048246383667\n","ppl in the first batch:  210.70993326982952\n","\n","Loss in the last batch:  5.388046741485596\n","ppl in the last batch:  218.77564255705477\n","\n","Average test loss along batches:  5.431026381081823\n","Averge test ppl along batches:  228.3835337073025\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.502564072608948\n","Average validation ppl along batches: :  245.3201451929707\n","\n","\n","Epoch  16\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.4600911140441895\n","ppl in the first batch:  235.11884601824292\n","\n","Loss in the last batch:  5.372734546661377\n","ppl in the last batch:  215.45122431954738\n","\n","Average test loss along batches:  5.393621608728324\n","Averge test ppl along batches:  219.99869372658986\n","\n","\n","Epoch  17\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.335742950439453\n","ppl in the first batch:  207.62694805194585\n","\n","Loss in the last batch:  5.294490814208984\n","ppl in the last batch:  199.23615191657845\n","\n","Average test loss along batches:  5.357933552479272\n","Averge test ppl along batches:  212.28581538827052\n","\n","\n","Epoch  18\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.182943820953369\n","ppl in the first batch:  178.20664803835365\n","\n","Loss in the last batch:  5.25087308883667\n","ppl in the last batch:  190.7327223942298\n","\n","Average test loss along batches:  5.324780332806267\n","Averge test ppl along batches:  205.36324394216183\n","\n","\n","Epoch  19\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.332975387573242\n","ppl in the first batch:  207.05312183681875\n","\n","Loss in the last batch:  5.198207378387451\n","ppl in the last batch:  180.94758042112164\n","\n","Average test loss along batches:  5.293165683746338\n","Averge test ppl along batches:  198.97231287159897\n","\n","\n","Epoch  20\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.325490474700928\n","ppl in the first batch:  205.50913278006556\n","\n","Loss in the last batch:  5.175397872924805\n","ppl in the last batch:  176.86697085801137\n","\n","Average test loss along batches:  5.262900002652289\n","Averge test ppl along batches:  193.04049830165056\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.3824178622319145\n","Average validation ppl along batches: :  217.54764026213778\n","\n","\n","Epoch  21\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.295108318328857\n","ppl in the first batch:  199.35921905453637\n","\n","Loss in the last batch:  5.296182155609131\n","ppl in the last batch:  199.5734134004775\n","\n","Average test loss along batches:  5.233654278416974\n","Averge test ppl along batches:  187.47664514337276\n","\n","\n","Epoch  22\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.243165016174316\n","ppl in the first batch:  189.2681923142352\n","\n","Loss in the last batch:  5.101714134216309\n","ppl in the last batch:  164.303303970358\n","\n","Average test loss along batches:  5.206255636984536\n","Averge test ppl along batches:  182.4097694860225\n","\n","\n","Epoch  23\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.15954065322876\n","ppl in the first batch:  174.0844720962534\n","\n","Loss in the last batch:  5.146116256713867\n","ppl in the last batch:  171.76310942404544\n","\n","Average test loss along batches:  5.179984424393653\n","Averge test ppl along batches:  177.68004349739851\n","\n","\n","Epoch  24\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.235356330871582\n","ppl in the first batch:  187.79601193984055\n","\n","Loss in the last batch:  5.351531028747559\n","ppl in the last batch:  210.93099218929072\n","\n","Average test loss along batches:  5.15509545022857\n","Averge test ppl along batches:  173.31234867270268\n","\n","\n","Epoch  25\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.143161296844482\n","ppl in the first batch:  171.25630549007522\n","\n","Loss in the last batch:  5.1721510887146\n","ppl in the last batch:  176.29365319273504\n","\n","Average test loss along batches:  5.130670659255401\n","Averge test ppl along batches:  169.1305089585079\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.295287975898156\n","Average validation ppl along batches: :  199.3950386647847\n","\n","\n","Epoch  26\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.062287330627441\n","ppl in the first batch:  157.95139049988842\n","\n","Loss in the last batch:  5.205399513244629\n","ppl in the last batch:  182.2536709813267\n","\n","Average test loss along batches:  5.107010378322282\n","Averge test ppl along batches:  165.17580281956697\n","\n","\n","Epoch  27\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.094020366668701\n","ppl in the first batch:  163.0440429846836\n","\n","Loss in the last batch:  5.071070671081543\n","ppl in the last batch:  159.34484195875257\n","\n","Average test loss along batches:  5.084361564078832\n","Averge test ppl along batches:  161.47681372326971\n","\n","\n","Epoch  28\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.054296970367432\n","ppl in the first batch:  156.69433085410765\n","\n","Loss in the last batch:  5.163334846496582\n","ppl in the last batch:  174.7462368661392\n","\n","Average test loss along batches:  5.06136019298838\n","Averge test ppl along batches:  157.8050156858987\n","\n","\n","Epoch  29\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.84119987487793\n","ppl in the first batch:  126.62119020345182\n","\n","Loss in the last batch:  4.986056804656982\n","ppl in the last batch:  146.35816531659407\n","\n","Average test loss along batches:  5.040133078530136\n","Averge test ppl along batches:  154.49057303632517\n","\n","--------- TEST --------\n","Average test loss along batches:  5.179844745274248\n","Average test ppl along batches:  177.65522703859784\n","\n","\n","Final average loss along runs:  5.172922942556184 +/- 0.3056242214967001\n","Final average ppl along runs:  176.42977865392072\n"]}],"source":["lossTs = [] # list that contains the losses computed on the test set in every run\n","\n","for run in tqdm(range(0, RUNS), desc = 'Run: '):\n","  # Instantiation of the model\n","  net = Network(HD_SIZE, EMB_DIM, len(trainCorpus.word2id), padding_idx = PAD_TOKEN).to(device)\n","  net.apply(init_weights)\n","\n","  # Cost function\n","  cost_function = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN) # the padding doesn't contribute to the input gradient\n","\n","  # Optimizer\n","  optimizer = optim.Adam(net.parameters(), lr = LEARNING_RATE_B)\n","\n","  # Training\n","  sampled_epochs = [] # list containing the number of the epochs in which a test on the valid set is performed\n","  losses_train = [] # list that contains the means of the losses for each training step in the sampled epochs\n","  losses_eval = [] # list that contains the means of the losses for each evaluation step (test step on the validation set) in the sampled epochs\n","  best_loss = math.inf # value of the best found loss\n","  patience = PATIENCE\n","\n","  for epoch in tqdm(range(EPOCHS_B), desc = 'Epoch: '):\n","    print(\"\\n\\nEpoch \", epoch)\n","    print(\"\\n--------- TRAIN --------\")\n","    loss = training_step(net, train_loader, optimizer, cost_function)\n","\n","    print(\"\\nAverage test loss along batches: \", sum(loss)/len(loss))\n","    print(\"Averge test ppl along batches: \", np.exp(sum(loss)/len(loss)))\n","\n","    if epoch % 5 == 0:\n","      sampled_epochs.append(epoch)\n","      losses_train.append(np.asarray(loss).mean())\n","\n","      # Compute the loss on the valid set\n","      print(\"\\n--------- VALIDATION --------\")\n","      lossV = test_step(net, valid_loader, cost_function)\n","      losses_eval.append(sum(lossV)/len(lossV))\n","      print(\"Average validation loss along batches: \", sum(lossV)/len(lossV))\n","      print(\"Average validation ppl along batches: : \", np.exp(sum(lossV)/len(lossV)))\n","\n","      # Check whether the performace of the model is deteriorating\n","      if best_loss > losses_eval[-1]:\n","        best_loss = losses_eval[-1]\n","      else:\n","        patience = patience - 1\n","\n","      # Early stopping\n","      if patience <= 0:\n","        break\n","\n","  # Testing\n","  print(\"\\n--------- TEST --------\")\n","  lossT = test_step(net, test_loader, cost_function)\n","  print(\"Average test loss along batches: \", sum(lossT)/len(lossT))\n","  print(\"Average test ppl along batches: \", np.exp(sum(lossT)/len(lossT)))\n","  lossTs.append(lossT)\n","\n","lossTs = np.asarray(lossTs)\n","print('\\n\\nFinal average loss along runs: ', lossTs.mean(), \"+/-\", lossTs.std())\n","print('Final average ppl along runs: ', np.exp(lossTs.mean()))"]},{"cell_type":"markdown","metadata":{"id":"B7f6bzDgya2Z"},"source":["</br>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"qFU6W0BRyWww"},"source":["# Model to improve the baseline\n","\n","</br>\n","\n","Here a **3-layers LSTM** is used. In addition, an embedding layer is used in order to convert the word ids into vector.\n","\n","</br>\n","\n","To improve the baseline two main regularization technique are used: \n","\n","*   *dropout* to the hidden-to-hidden connections of the RNN\n","\n","*   *Variational dropout*.\n","\n","</br>\n","\n","Moreover, in order to make the training process more stable, the following methods were applied:\n","\n","\n","*   *zeroing* of the *initial hidden state* at the beginning of every training epoch\n","*   a *weight decay* (L2 penalty) is added to the optimizer\n","*   an *adaptive learning rate* is designed. It decreases the learning rate if no improvement on the loss value is observed for 5 epochs."]},{"cell_type":"markdown","metadata":{"id":"hWlh4ZRdyRzG"},"source":["#### Definition of the Neural Network\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fPy20MxR3NlE"},"outputs":[],"source":["\"\"\"\n","Class for the implementation of the Variational dropout.\n","\"\"\"\n","class VariationalDropout(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","  \"\"\"\n","  Function that returns the dropout version of the input/output matrix of a forward or backward pass.\n","  :param samples: input/output matrix to mask with the dropout\n","  :param dropout: probability of dropout\n","  :return masked_s: dropout input/output matrix\n","  \"\"\"\n","  def forward(self, samples, dropout = 0.5):\n","    new_samples = samples.data.new(1, samples.size(1), samples.size(2))\n","    change = new_samples.bernoulli_(1 - dropout)\n","    m = torch.tensor(torch.div(change, (1 - dropout)), requires_grad = False)\n","    mask = m.expand_as(samples)\n","    masked_s = mask*samples\n","\n","    return masked_s"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7iNN5Q0f36CE"},"outputs":[],"source":["\"\"\"\n","Class that defines the structure of the neural network.\n",":attribute hidden_size: the number of features in the hidden state\n",":attribute embedding_dim: the size of each embedding vector\n",":attribute num_embeddings: size of the dictionary of embeddings\n",":attribute num_layers: number of recurrent layers. Default: 3\n",":attribute padding_idx: when the input is equal to the specified value its embedding will\n","                        be a sequence of zeros of 'embedding_dim' length\n","\"\"\"\n","class ImprovedNetwork(nn.Module):\n","  def __init__(self, hidden_size, embedding_dim, num_embeddings, num_layers = 3, padding_idx = 0):\n","    super(ImprovedNetwork, self).__init__()\n","    self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx = padding_idx)\n","    self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, dropout = 0.2) # here the hidden-to-hidden dropout is defined\n","    self.linear = nn.Linear(hidden_size, num_embeddings)\n","    self.var = VariationalDropout() # here the Variational dropout is defined\n","\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","\n","  \"\"\"\n","  Function that specify how to do a forward pass in the network.\n","  :param sents_ids: Tensor [batch_size, maximum_length] containing the sentences of the batch with word ids\n","  :param sent_lengths: length of each word in the batch before the padding\n","  :param hidden: hidden states of the network\n","  \"\"\"\n","  def forward(self, sents_ids, sent_lengths, hidden):\n","    embed = self.embedding(sents_ids) # embedding of the input. Tensor [batch_size, maximum_length, embedding_dim]\n","    embed = self.var(embed) # Variational dropout\n","    embed = embed.permute(1, 0, 2) # Tensor [maximum_length, batch_size, embedding_dim]\n","\n","    # Pack the input in order to remove from the computation the padding embeddings\n","    packed_input = pack_padded_sequence(embed, sent_lengths.cpu().numpy())\n","\n","    # Pass the input into the lstms. Each will return the packed output features,\n","    # a tensor containing the final hidden state for each element in the sequence and\n","    # a tensor containing the final cell state for each element in the sequence\n","    packed_output, hidden = self.lstm(packed_input)\n","\n","    # Unpack the output in order to add the previously removed padding\n","    output, input_sizes = pad_packed_sequence(packed_output)\n","    output = self.var(output) # Variational dropout\n","\n","    # Decode hidden states of all time steps\n","    output = self.linear(output)\n","    output = output.permute(1, 2, 0)\n","\n","    return output, hidden\n","\n","  \"\"\"\n","  Function that zeroes the initial hidden states.\n","  :return: the zeroed hidden states\n","  \"\"\"\n","  def init_hidden(self):\n","    return (torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size), torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size))"]},{"cell_type":"markdown","metadata":{"id":"Wo9HAKzt7Vdx"},"source":["#### Implementation of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RGnWqMwK7bUB"},"outputs":[],"source":["# Training step\n","\"\"\"\n","Function that defines the training procedure.\n",":param net: network to train\n",":param data_loader: dataloader for the training procedure\n",":param optimizer: optimizer used to update the parameters\n",":param cost_function: cost function for the loss computation\n",":return loss_array: training loss for each sample in the dataloader\n","\"\"\"\n","def training_step(net, data_loader, optimizer, cost_function):\n","  loss_array = []\n","  hidden = net.init_hidden()\n","\n","  # Set the network to training mode\n","  net.train() \n","\n","  # Iterate over the training set\n","  for idx, (sample, length, target, _ )in enumerate(data_loader):\n","    # Forward pass\n","    output, hidden = net(sample, length, hidden)\n","\n","    # Loss computation\n","    loss = cost_function(output, target)\n","    loss_array.append(loss.item())\n","\n","    if idx == 1:\n","      print(\"Loss in the first batch: \", loss.item())\n","      print(\"ppl in the first batch: \", np.exp(loss.item()))\n","      \n","    # Backward pass\n","    loss.backward()\n","\n","    # Parameters update\n","    #torch.nn.utils.clip_grad_norm_(net.parameters(), 0.25)\n","    optimizer.step()\n","\n","    # Gradients reset\n","    optimizer.zero_grad()\n","\n","  print(\"\\nLoss in the last batch: \", loss_array[-1])\n","  print(\"ppl in the last batch: \", np.exp(loss_array[-1]))\n","\n","  return loss_array\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a8aSupp27zQW"},"outputs":[],"source":["# Test step\n","\"\"\"\n","Function that defines the test procedure\n","\n",":param net: network to test\n",":param data_loader: dataloader for the test procedure\n",":param cost_function: cost function for the loss computation\n",":param save: boolean. If True then the output words and their perplexity are saved into a file\n","                      otherwhise not.\n","             Default: False\n",":param corpus: corpus used to convert the word id into words. Used in the saving procedure\n",":return losses: list containing the losses along batches\n","\"\"\"\n","def test_step(net, data_loader, cost_function, save = False, corpus = trainCorpus):\n","  losses = [] # list containing the losses along batches\n","  predictions = [] # list containing the output of the network along batches\n","  samples = [] # list containing the inputs along batches\n","  targets = [] # list containing the targets along batches\n","  ls = [] # list containing the per word losses along batches\n","  hidden = net.init_hidden()\n","\n","  # Set the network to evaluation mode\n","  net.eval() \n","\n","  # Disable gradient computation \n","  with torch.no_grad():\n","    # Iterate over the test set\n","    for sample, length, target, _ in data_loader:\n","      # Forward pass\n","      output, hidden = net(sample, length, hidden)\n","\n","      # Loss computation\n","      loss = cost_function(output, target)\n","      losses.append(loss.item())\n","\n","      if save:\n","        # Store the samples along batches\n","        for s in sample:\n","          samples.append(s.tolist())\n","\n","        # Store the targets along batches\n","        for s in target:\n","          targets.append(s.tolist())\n","\n","        # Compute the predictions from the current output of the network\n","        softmax = nn.Softmax(1)\n","        out_soft = softmax(output)\n","        max_probs, prediction = out_soft.max(1)\n","\n","        # Store the predictions along batches\n","        for pred in prediction.tolist():\n","          predictions.append(pred)\n","\n","        # Compute the loss per word\n","        lf = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN, reduction = \"none\")\n","        l = lf(output, target)\n","        ls.append(l)\n","\n","\n","    if save:\n","      d_out = decoder(predictions, corpus) # output word_ids --> words\n","      d_in = decoder(samples, corpus) # input word_ids --> words\n","      d_t = decoder(targets, corpus) # target word_ids --> words\n","\n","      with open(path.join(SAVE, \"output.txt\"), 'w') as f:\n","        for sent in d_out:\n","          for word in sent:\n","            f.write(\"%s \" % word)\n","          f.write(\"\\n\\n\")\n","      f.close()\n","\n","      with open(path.join(SAVE, \"input.txt\"), 'w') as f:\n","        for sent in d_in:\n","          for word in sent:\n","            f.write(\"%s \" % word)\n","          f.write(\"\\n\\n\")\n","      f.close()\n","\n","      with open(path.join(SAVE, \"target.txt\"), 'w') as f:\n","        for sent in d_t:\n","          for word in sent:\n","            f.write(\"%s \" % word)\n","          f.write(\"\\n\\n\")\n","      f.close()\n","\n","      with open(path.join(SAVE, \"loss_per_word.txt\"), 'w') as f:\n","        for l in ls:\n","          for sent in l:\n","            for l_word in sent:\n","              f.write(\"%s \" % l_word.item())\n","            f.write(\"\\n\\n\")\n","      f.close()\n","\n","  return losses"]},{"cell_type":"markdown","metadata":{"id":"rSz2L0OA85NF"},"source":["#### Training and test\n","Since we have a small corpora, to have reliable results the model is trained and tested from scratch for several runs.\n","The results of the runs are then averaged and the standard deviation is computed.\n","\n","</br>\n","\n","In addition, as aforementioned, a weight decay and an adaptive learning rate are applied."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AT-OWkXW9CSC"},"outputs":[],"source":["\"\"\"\n","Function that write a list of losses in a file.\n",":param losses: list of losses\n",":param path: name of the file\n","\"\"\"\n","def loss_to_file(losses, p):\n","  if not path.exists(path.join(SAVE, \"Losses/\")):\n","    mkdir(path.join(SAVE, \"Losses/\"))\n","\n","  with open(path.join(SAVE, \"Losses/\", p + \".txt\"), 'w') as f:\n","    for item in losses:\n","      f.write(\"%s\\n\" % item)\n","\n","    f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJb2Vuhg9QTq","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["298435ec7dd843dd9a3342845b118754","fe0e2d5b6d9942af9db79d53bb79c28a","913eddd4ac0e4df7af30a9a4bb0b2f0f","e9d8bee9e7764ed9902d4e8126c5b629","9e03acb83b044de39a9543c091a4a4f2","879ec6b7fd0a4279ad042fa6e8977af2","72cc716bf16b4b57992dfbaf44466c36","1a499a4ae3a5482aa109282f7d1f6422","13f4814106514efa8e51756b7883b915","59bc24312b2b4d77935850e606b32856","cb2cd2932cd84acca0b37d7c2a970760","b0d8a32214ef438aa2d45299a788c848","10a86d60424f433baa4926e3743aec1b","5b90c9eea6ed4f8bacc5f2721737d16e","b687bcb065004a459288dcd802d27a87","0fca38423edc41e4b77301434a3b0a64","85e82f958c894177b64d0e1a6c315cc7","98a7a424579b437f998e88194f13e925","455ca76addc040f79a7523f3c1e8b125","0bd32810c4c64ec6b2f7b8857c48faaa","1e106598ace640a1ac8651ff2f1dda88","af7aee7f27b24a838c9a240f0113556b","430c35b33945400a887cb598b36e1faa","aa0f8a9ac6a34a39ae2d613fa500fb34","c8128784d6c5485fb16d8787e94a5c47","c5b05b4eebe841a9b1afaa99967bf410","3ae3240d01fa419091a1cce7b0264633","b194a16d1bc1404eb49877f7be1a42b5","25666c93ad014582ae956be0ca81a980","ff0b9f91145a4a15b9629942c43276b4","03631c08750e41daa9a087f268ce05f2","0c6ca64d794a4e26bb983da824b39950","43a6f60e280c4c35a6794270dba1444a","a776f4cd02ad419e8ba1f10c4be53bfc","07ada2015c104e0aa966e3322721ecfe","51460f5b41ea475795afe7e63fe291da","2de5fb2ac52e4659874760e363599247","3c10091b396b402288dcdf5ac3098fcd","04d5dc5f24054e15bc29bf1a84ec7aba","b420d4bbff004c939037f02d76fa445b","98c0218cd0834aa9bef016a957dcccb3","082bc469a79d406688f6650bc69dde6e","51c1c7f5c8564765a6d5d86dd47a6f68","cc810cebed9942078990f283610e4816","f22bb5490f7a4a7ebb259844e34fdb36","4d8abed111544a41b967301d8145425b","755c376ef4d64775b2bcc975b943937e","69a4952f5bdb42ab92648020e3c7e5d1","c2f037558e864a0383970e9470379455","7f03bc8ad8a045fe9e179013fda02631","9b6cfacf20f24ab89207e3a81e243e18","831b55e1bf0b4f3790b73f908bbe3df2","300a5a02e7e442e3811dd02bdefb3414","6a5fe464f66145f2bcebb80cf3b48369","30a9d4693cd94de080be200ba99bf482","825e714725df4b26997fe2ac67dbc149","150bf6df0a4245b884db8dfd28a3ecd1","97d02fe8e10f47469fc74fc1a3894543","701b3aa3d91247599e7b303d35b19c81","1aed861e240041eeab083b4e442a7619","48bcb4f3503f4ed5af4690541fa73f7d","d2430f0eea50470db6a98060e38451ee","700eb13d764447a2b32c0bd83f341787","36244f7924d54c7da5c05602087b721d","56957c1e88fc4f499942c339920f563f","b00dce6b6b314cd1b26e228799c84db1"]},"executionInfo":{"status":"ok","timestamp":1658313462242,"user_tz":-120,"elapsed":5830462,"user":{"displayName":"Uda Colab","userId":"13503574252864910777"}},"outputId":"8c8b50b0-3228-4516-caed-fbfa0589cfc5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Run:   0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"298435ec7dd843dd9a3342845b118754"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d8a32214ef438aa2d45299a788c848"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Epoch  0\n","\n","--------- TRAIN --------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["Loss in the first batch:  9.208457946777344\n","ppl in the first batch:  9981.19345452262\n","\n","Loss in the last batch:  6.630674839019775\n","ppl in the last batch:  757.9935216877559\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.709643318228526\n","Averge test ppl along batches:  820.2780090523963\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.594133120316726\n","Average validation ppl along batches: :  730.7951005964717\n","\n","\n","Epoch  1\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.541275978088379\n","ppl in the first batch:  693.1704843435596\n","\n","Loss in the last batch:  6.400829315185547\n","ppl in the last batch:  602.344364122138\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.5145645025476835\n","Averge test ppl along batches:  674.8999802917882\n","\n","\n","Epoch  2\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.363516807556152\n","ppl in the first batch:  580.2835176015511\n","\n","Loss in the last batch:  5.943002700805664\n","ppl in the last batch:  381.0774749597424\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.2458391429082445\n","Averge test ppl along batches:  515.8619252289546\n","\n","\n","Epoch  3\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.294098854064941\n","ppl in the first batch:  541.36777514447\n","\n","Loss in the last batch:  5.942570686340332\n","ppl in the last batch:  380.9128795345099\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.962208835683094\n","Averge test ppl along batches:  388.46723757410433\n","\n","\n","Epoch  4\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.847026824951172\n","ppl in the first batch:  346.20352509872424\n","\n","Loss in the last batch:  5.689897537231445\n","ppl in the last batch:  295.86330411409955\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.773374460966438\n","Averge test ppl along batches:  321.6212017484199\n","\n","\n","Epoch  5\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.793461799621582\n","ppl in the first batch:  328.1470396743652\n","\n","Loss in the last batch:  5.528630256652832\n","ppl in the last batch:  251.79877500670273\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.636614319759236\n","Averge test ppl along batches:  280.51138707154036\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.615464705687303\n","Average validation ppl along batches: :  274.64097676929646\n","\n","\n","Epoch  6\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.384567737579346\n","ppl in the first batch:  218.01584367998706\n","\n","Loss in the last batch:  5.447424411773682\n","ppl in the last batch:  232.15944807224864\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.527828956847866\n","Averge test ppl along batches:  251.59708951346397\n","\n","\n","Epoch  7\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.427666187286377\n","ppl in the first batch:  227.61740865952663\n","\n","Loss in the last batch:  5.386560916900635\n","ppl in the last batch:  218.45082170191725\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.440328807772748\n","Averge test ppl along batches:  230.51796710017513\n","\n","\n","Epoch  8\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.246910572052002\n","ppl in the first batch:  189.9784362031578\n","\n","Loss in the last batch:  5.082845211029053\n","ppl in the last batch:  161.2321434144777\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.367708428265297\n","Averge test ppl along batches:  214.3710577539777\n","\n","\n","Epoch  9\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.22832727432251\n","ppl in the first batch:  186.48061157987996\n","\n","Loss in the last batch:  5.195154666900635\n","ppl in the last batch:  180.39604193611046\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.305273886322068\n","Averge test ppl along batches:  201.39615451268676\n","\n","\n","Epoch  10\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.199596405029297\n","ppl in the first batch:  181.1990960716344\n","\n","Loss in the last batch:  5.148044109344482\n","ppl in the last batch:  172.09456278034662\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.251117609044369\n","Averge test ppl along batches:  190.77936610155683\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.3579715215242825\n","Average validation ppl along batches: :  212.29387583097275\n","\n","\n","Epoch  11\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.472343921661377\n","ppl in the first batch:  238.01743366007923\n","\n","Loss in the last batch:  5.078357219696045\n","ppl in the last batch:  160.51015630004625\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.205352485633513\n","Averge test ppl along batches:  182.24510022809605\n","\n","\n","Epoch  12\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.021299839019775\n","ppl in the first batch:  151.6082420810657\n","\n","Loss in the last batch:  5.227593421936035\n","ppl in the last batch:  186.34381253933134\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.160655476005473\n","Averge test ppl along batches:  174.27865364971643\n","\n","\n","Epoch  13\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.241818904876709\n","ppl in the first batch:  189.01358766382708\n","\n","Loss in the last batch:  4.9658203125\n","ppl in the last batch:  143.4261562987415\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.122448858786573\n","Averge test ppl along batches:  167.7456524686475\n","\n","\n","Epoch  14\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.0625901222229\n","ppl in the first batch:  157.99922409486265\n","\n","Loss in the last batch:  5.175449371337891\n","ppl in the last batch:  176.87607946087516\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.08879589780462\n","Averge test ppl along batches:  162.19444573830077\n","\n","\n","Epoch  15\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.098254680633545\n","ppl in the first batch:  163.735886360116\n","\n","Loss in the last batch:  5.105673313140869\n","ppl in the last batch:  164.95509958499028\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.05658358816324\n","Averge test ppl along batches:  157.0530408595854\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.251431332184718\n","Average validation ppl along batches: :  190.83922739284912\n","\n","\n","Epoch  16\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.953698635101318\n","ppl in the first batch:  141.69808541987823\n","\n","Loss in the last batch:  4.927778720855713\n","ppl in the last batch:  138.07247395043487\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.026619107755896\n","Averge test ppl along batches:  152.41683572016817\n","\n","\n","Epoch  17\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.655435085296631\n","ppl in the first batch:  105.15496142505091\n","\n","Loss in the last batch:  5.078139781951904\n","ppl in the last batch:  160.4752591278674\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.997962445066037\n","Averge test ppl along batches:  148.11106700711642\n","\n","\n","Epoch  18\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.125460624694824\n","ppl in the first batch:  168.25162465844429\n","\n","Loss in the last batch:  4.949239730834961\n","ppl in the last batch:  141.06767373940832\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.974126064614074\n","Averge test ppl along batches:  144.62237928861617\n","\n","\n","Epoch  19\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.253767967224121\n","ppl in the first batch:  191.28567040253114\n","\n","Loss in the last batch:  5.154943466186523\n","ppl in the last batch:  173.28600996299727\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.94953531761692\n","Averge test ppl along batches:  141.10937764238503\n","\n","\n","Epoch  20\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.026081085205078\n","ppl in the first batch:  152.3348540813892\n","\n","Loss in the last batch:  5.2055134773254395\n","ppl in the last batch:  182.27444253699758\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.927103615242596\n","Averge test ppl along batches:  137.97929190565387\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.198157865267533\n","Average validation ppl along batches: :  180.93862136367068\n","\n","\n","Epoch  21\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.974634170532227\n","ppl in the first batch:  144.69588144728957\n","\n","Loss in the last batch:  4.939908027648926\n","ppl in the last batch:  139.75739515267477\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.906809735697336\n","Averge test ppl along batches:  135.20737834768553\n","\n","\n","Epoch  22\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.816330432891846\n","ppl in the first batch:  123.51102617992484\n","\n","Loss in the last batch:  4.866640567779541\n","ppl in the last batch:  129.88384717334847\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.886962229439838\n","Averge test ppl along batches:  132.55030442857134\n","\n","\n","Epoch  23\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.8414435386657715\n","ppl in the first batch:  126.65204696146243\n","\n","Loss in the last batch:  4.791164875030518\n","ppl in the last batch:  120.441586375909\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.8673135853249185\n","Averge test ppl along batches:  129.97129070357167\n","\n","\n","Epoch  24\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.712602138519287\n","ppl in the first batch:  111.34150930898535\n","\n","Loss in the last batch:  4.820956707000732\n","ppl in the last batch:  124.08374580001335\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.852062919187038\n","Averge test ppl along batches:  128.00417994247803\n","\n","\n","Epoch  25\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.821165084838867\n","ppl in the first batch:  124.10960479683817\n","\n","Loss in the last batch:  4.814222812652588\n","ppl in the last batch:  123.25098597064016\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.833151516123268\n","Averge test ppl along batches:  125.60618747080228\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.174152314662933\n","Average validation ppl along batches: :  176.64680988133216\n","\n","\n","Epoch  26\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.942352294921875\n","ppl in the first batch:  140.09941740641713\n","\n","Loss in the last batch:  4.780084133148193\n","ppl in the last batch:  119.11437109029178\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.817738146179525\n","Averge test ppl along batches:  123.6850167283242\n","\n","\n","Epoch  27\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.659744739532471\n","ppl in the first batch:  105.60912088216038\n","\n","Loss in the last batch:  4.721522808074951\n","ppl in the last batch:  112.33919351073936\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.801576483739566\n","Averge test ppl along batches:  121.70212779049925\n","\n","\n","Epoch  28\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.68553352355957\n","ppl in the first batch:  108.36807380806358\n","\n","Loss in the last batch:  4.488658905029297\n","ppl in the last batch:  89.00200566404601\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.790134860318908\n","Averge test ppl along batches:  120.3175936381865\n","\n","\n","Epoch  29\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.948404788970947\n","ppl in the first batch:  140.94993959036884\n","\n","Loss in the last batch:  4.571372032165527\n","ppl in the last batch:  96.67666230922309\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.748267546091994\n","Averge test ppl along batches:  115.38421343876503\n","\n","\n","Epoch  30\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.689994812011719\n","ppl in the first batch:  108.85261507985966\n","\n","Loss in the last batch:  4.788497447967529\n","ppl in the last batch:  120.12074532918258\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.741376235967721\n","Averge test ppl along batches:  114.59179856482449\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.16299170255661\n","Average validation ppl along batches: :  174.68628404073834\n","\n","\n","Epoch  31\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.695871353149414\n","ppl in the first batch:  109.49417518119823\n","\n","Loss in the last batch:  4.511954307556152\n","ppl in the last batch:  91.09968145029778\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.7358012163112875\n","Averge test ppl along batches:  113.95472453554316\n","\n","\n","Epoch  32\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.665745258331299\n","ppl in the first batch:  106.2447354988973\n","\n","Loss in the last batch:  4.550507068634033\n","ppl in the last batch:  94.68040560887633\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.734356914299627\n","Averge test ppl along batches:  113.79025829570864\n","\n","\n","Epoch  33\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.642010688781738\n","ppl in the first batch:  103.75275248987022\n","\n","Loss in the last batch:  4.838244438171387\n","ppl in the last batch:  126.24752173883378\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.729871239654913\n","Averge test ppl along batches:  113.28097531209112\n","\n","\n","Epoch  34\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.803365707397461\n","ppl in the first batch:  121.92007503679959\n","\n","Loss in the last batch:  4.752537250518799\n","ppl in the last batch:  115.8779231729441\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.727274769154495\n","Averge test ppl along batches:  112.9872261220177\n","\n","\n","Epoch  35\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.879698276519775\n","ppl in the first batch:  131.59095381484997\n","\n","Loss in the last batch:  4.790101528167725\n","ppl in the last batch:  120.31358326080297\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.72366360732591\n","Averge test ppl along batches:  112.57994678232407\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.158204780175136\n","Average validation ppl along batches: :  173.85207260359644\n","\n","\n","Epoch  36\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.739312648773193\n","ppl in the first batch:  114.35557221736975\n","\n","Loss in the last batch:  4.995776653289795\n","ppl in the last batch:  147.78768061129733\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.719120518439074\n","Averge test ppl along batches:  112.06964612554036\n","\n","\n","Epoch  37\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.8415913581848145\n","ppl in the first batch:  126.67076998991051\n","\n","Loss in the last batch:  4.828549385070801\n","ppl in the last batch:  125.02945944195201\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.719790563917233\n","Averge test ppl along batches:  112.14476304823242\n","\n","\n","Epoch  38\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.783715724945068\n","ppl in the first batch:  119.54773228242802\n","\n","Loss in the last batch:  4.845997333526611\n","ppl in the last batch:  127.23010959240705\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.720340550943778\n","Averge test ppl along batches:  112.20645817720904\n","\n","\n","Epoch  39\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.774782657623291\n","ppl in the first batch:  118.48456010615418\n","\n","Loss in the last batch:  4.347715377807617\n","ppl in the last batch:  77.30165595489787\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.7176606477304865\n","Averge test ppl along batches:  111.90615829642212\n","\n","--------- TEST --------\n","Average test loss along batches:  5.074178231173549\n","Average test ppl along batches:  159.84078581905675\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"430c35b33945400a887cb598b36e1faa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Epoch  0\n","\n","--------- TRAIN --------\n","Loss in the first batch:  9.208430290222168\n","ppl in the first batch:  9980.917412912322\n","\n","Loss in the last batch:  6.630721092224121\n","ppl in the last batch:  758.0285821278298\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.702695182469338\n","Averge test ppl along batches:  814.5983604195939\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.5835875272750854\n","Average validation ppl along batches: :  723.1289260928494\n","\n","\n","Epoch  1\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.690536975860596\n","ppl in the first batch:  804.7542697586575\n","\n","Loss in the last batch:  6.383333683013916\n","ppl in the last batch:  591.897621346452\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.449563937281546\n","Averge test ppl along batches:  632.4264550761251\n","\n","\n","Epoch  2\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.300442695617676\n","ppl in the first batch:  544.8130430943672\n","\n","Loss in the last batch:  5.955663204193115\n","ppl in the last batch:  385.9327780591515\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.10190783824369\n","Averge test ppl along batches:  446.70920653077764\n","\n","\n","Epoch  3\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.806600093841553\n","ppl in the first batch:  332.4867779833234\n","\n","Loss in the last batch:  5.638274192810059\n","ppl in the last batch:  280.97738700676365\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.856931888893859\n","Averge test ppl along batches:  349.6497324283362\n","\n","\n","Epoch  4\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.622050762176514\n","ppl in the first batch:  276.45574728731754\n","\n","Loss in the last batch:  5.527803897857666\n","ppl in the last batch:  251.59078482345836\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.6888959832387425\n","Averge test ppl along batches:  295.56712938282016\n","\n","\n","Epoch  5\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.663488388061523\n","ppl in the first batch:  288.15207762052506\n","\n","Loss in the last batch:  5.62515115737915\n","ppl in the last batch:  277.3141994427684\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.564051463360837\n","Averge test ppl along batches:  260.8776343195214\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.568694564012381\n","Average validation ppl along batches: :  262.0917318407352\n","\n","\n","Epoch  6\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.364927768707275\n","ppl in the first batch:  213.77579282138535\n","\n","Loss in the last batch:  5.5426411628723145\n","ppl in the last batch:  255.35153460159253\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.46866276928279\n","Averge test ppl along batches:  237.14286591418204\n","\n","\n","Epoch  7\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.439273834228516\n","ppl in the first batch:  230.27490497801176\n","\n","Loss in the last batch:  5.4901652336120605\n","ppl in the last batch:  242.29723919854396\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.388042582768827\n","Averge test ppl along batches:  218.77473273301342\n","\n","\n","Epoch  8\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.239602565765381\n","ppl in the first batch:  188.59513334654298\n","\n","Loss in the last batch:  5.4016876220703125\n","ppl in the last batch:  221.78038202641295\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.322501445288346\n","Averge test ppl along batches:  204.89577706342885\n","\n","\n","Epoch  9\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.313106060028076\n","ppl in the first batch:  202.97971745353954\n","\n","Loss in the last batch:  5.3390583992004395\n","ppl in the last batch:  208.3164669603065\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.2636610674168605\n","Averge test ppl along batches:  193.1874705436465\n","\n","\n","Epoch  10\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.108895778656006\n","ppl in the first batch:  165.48751909597286\n","\n","Loss in the last batch:  5.230534553527832\n","ppl in the last batch:  186.89268096480532\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.211727447161391\n","Averge test ppl along batches:  183.410616845265\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.33376788176023\n","Average validation ppl along batches: :  207.21727526900116\n","\n","\n","Epoch  11\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.238767147064209\n","ppl in the first batch:  188.4376432394453\n","\n","Loss in the last batch:  5.127531051635742\n","ppl in the last batch:  168.60033822340188\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.16661478939666\n","Averge test ppl along batches:  175.32033553581087\n","\n","\n","Epoch  12\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.266470909118652\n","ppl in the first batch:  193.73106009729585\n","\n","Loss in the last batch:  5.0371928215026855\n","ppl in the last batch:  154.0369981833717\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.12877297728029\n","Averge test ppl along batches:  168.8098573838003\n","\n","\n","Epoch  13\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.875940322875977\n","ppl in the first batch:  131.097369125537\n","\n","Loss in the last batch:  5.0356550216674805\n","ppl in the last batch:  153.80030215515188\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.090862926645729\n","Averge test ppl along batches:  162.53005307103425\n","\n","\n","Epoch  14\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.324654579162598\n","ppl in the first batch:  205.33742038969737\n","\n","Loss in the last batch:  5.052864074707031\n","ppl in the last batch:  156.46996501222685\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.0555397923497125\n","Averge test ppl along batches:  156.88919507868047\n","\n","\n","Epoch  15\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.114497661590576\n","ppl in the first batch:  166.41716225004078\n","\n","Loss in the last batch:  5.08011531829834\n","ppl in the last batch:  160.79259718820688\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.0250188836224\n","Averge test ppl along batches:  152.17312966545802\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.233055454034072\n","Average validation ppl along batches: :  187.3644131640128\n","\n","\n","Epoch  16\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.156083106994629\n","ppl in the first batch:  173.4836063444886\n","\n","Loss in the last batch:  5.118899822235107\n","ppl in the last batch:  167.15137220166076\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.997487902096962\n","Averge test ppl along batches:  148.04079861563025\n","\n","\n","Epoch  17\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.880192279815674\n","ppl in the first batch:  131.65597623906854\n","\n","Loss in the last batch:  5.202446937561035\n","ppl in the last batch:  181.71634685956224\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.970451575617449\n","Averge test ppl along batches:  144.09194108874433\n","\n","\n","Epoch  18\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.8246283531188965\n","ppl in the first batch:  124.5401748137562\n","\n","Loss in the last batch:  4.977262496948242\n","ppl in the last batch:  145.07668967973277\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.946234661694531\n","Averge test ppl along batches:  140.6443919404127\n","\n","\n","Epoch  19\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.932198524475098\n","ppl in the first batch:  138.6840777592798\n","\n","Loss in the last batch:  5.243640899658203\n","ppl in the last batch:  189.35828335570176\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.922810740303957\n","Averge test ppl along batches:  137.388233638698\n","\n","\n","Epoch  20\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.678285598754883\n","ppl in the first batch:  107.58546971169892\n","\n","Loss in the last batch:  4.817149639129639\n","ppl in the last batch:  123.61224863838147\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.900911655600212\n","Averge test ppl along batches:  134.41226153678653\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.181263891550211\n","Average validation ppl along batches: :  177.90752477380727\n","\n","\n","Epoch  21\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.625299453735352\n","ppl in the first batch:  102.03332276799591\n","\n","Loss in the last batch:  4.947624683380127\n","ppl in the last batch:  140.8400266318994\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.878917835618807\n","Averge test ppl along batches:  131.4882949171075\n","\n","\n","Epoch  22\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.774299144744873\n","ppl in the first batch:  118.42728514315611\n","\n","Loss in the last batch:  5.109317779541016\n","ppl in the last batch:  165.55736971296392\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.859963750911811\n","Averge test ppl along batches:  129.0195251824652\n","\n","\n","Epoch  23\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.831402778625488\n","ppl in the first batch:  125.38672716597847\n","\n","Loss in the last batch:  4.6876020431518555\n","ppl in the last batch:  108.5924672930631\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.843657037075977\n","Averge test ppl along batches:  126.93270156573043\n","\n","\n","Epoch  24\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.6663126945495605\n","ppl in the first batch:  106.30503971759983\n","\n","Loss in the last batch:  4.786957263946533\n","ppl in the last batch:  119.93587967674274\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.824975590727645\n","Averge test ppl along batches:  124.58342735527158\n","\n","\n","Epoch  25\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.030379295349121\n","ppl in the first batch:  152.99103047829925\n","\n","Loss in the last batch:  4.886205673217773\n","ppl in the last batch:  132.45006059584844\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.810078542526454\n","Averge test ppl along batches:  122.74125754715196\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.1635630039068365\n","Average validation ppl along batches: :  174.78611106361816\n","\n","\n","Epoch  26\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.7617692947387695\n","ppl in the first batch:  116.95266669022104\n","\n","Loss in the last batch:  4.694732189178467\n","ppl in the last batch:  109.36951437983095\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.794056718933709\n","Averge test ppl along batches:  120.79038874107827\n","\n","\n","Epoch  27\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.61870002746582\n","ppl in the first batch:  101.36217839707804\n","\n","Loss in the last batch:  5.00251579284668\n","ppl in the last batch:  148.7870059300074\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.779320414933621\n","Averge test ppl along batches:  119.02343600428351\n","\n","\n","Epoch  28\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.780239582061768\n","ppl in the first batch:  119.13288872910498\n","\n","Loss in the last batch:  4.749502182006836\n","ppl in the last batch:  115.52675891045457\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.764753592068746\n","Averge test ppl along batches:  117.30220953162252\n","\n","\n","Epoch  29\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.6807169914245605\n","ppl in the first batch:  107.8473704969219\n","\n","Loss in the last batch:  4.763774394989014\n","ppl in the last batch:  117.18740376851026\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.749900332324581\n","Averge test ppl along batches:  115.5727650843015\n","\n","\n","Epoch  30\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.7063751220703125\n","ppl in the first batch:  110.65033809969708\n","\n","Loss in the last batch:  4.746600151062012\n","ppl in the last batch:  115.19198268158013\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.738596998937598\n","Averge test ppl along batches:  114.2737629477997\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.142340884758876\n","Average validation ppl along batches: :  171.1158623658105\n","\n","\n","Epoch  31\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.618321418762207\n","ppl in the first batch:  101.32380905806089\n","\n","Loss in the last batch:  4.70515775680542\n","ppl in the last batch:  110.51571817897893\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.725541749138447\n","Averge test ppl along batches:  112.79158657018476\n","\n","\n","Epoch  32\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.757490634918213\n","ppl in the first batch:  116.45333501131141\n","\n","Loss in the last batch:  4.522017002105713\n","ppl in the last batch:  92.02101750558494\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.68482200631268\n","Averge test ppl along batches:  108.29099547906884\n","\n","\n","Epoch  33\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.486415863037109\n","ppl in the first batch:  88.80259415575327\n","\n","Loss in the last batch:  4.550008773803711\n","ppl in the last batch:  94.63323860474172\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.678465272737965\n","Averge test ppl along batches:  107.60480175824466\n","\n","\n","Epoch  34\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.787158489227295\n","ppl in the first batch:  119.96001623616563\n","\n","Loss in the last batch:  4.872363090515137\n","ppl in the last batch:  130.62924117471093\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.674869516305909\n","Averge test ppl along batches:  107.21857590339434\n","\n","\n","Epoch  35\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.6064605712890625\n","ppl in the first batch:  100.12912182063013\n","\n","Loss in the last batch:  4.867438316345215\n","ppl in the last batch:  129.98750316634784\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.671845082641555\n","Averge test ppl along batches:  106.89479031381747\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.1420227610147915\n","Average validation ppl along batches: :  171.0614350047794\n","\n","\n","Epoch  36\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.6576828956604\n","ppl in the first batch:  105.39159569198688\n","\n","Loss in the last batch:  4.632547378540039\n","ppl in the last batch:  102.77553913399694\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.667732570450782\n","Averge test ppl along batches:  106.456086890417\n","\n","\n","Epoch  37\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.9182538986206055\n","ppl in the first batch:  136.7636014646783\n","\n","Loss in the last batch:  4.816486358642578\n","ppl in the last batch:  123.53028623093562\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.666613365417202\n","Averge test ppl along batches:  106.33700735175371\n","\n","\n","Epoch  38\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.407272815704346\n","ppl in the first batch:  82.04540517836499\n","\n","Loss in the last batch:  4.769113063812256\n","ppl in the last batch:  117.814701484963\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.6621213772162635\n","Averge test ppl along batches:  105.86041399666016\n","\n","\n","Epoch  39\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.6368632316589355\n","ppl in the first batch:  103.22006182243545\n","\n","Loss in the last batch:  4.625209808349609\n","ppl in the last batch:  102.02417636139052\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.657889715249861\n","Averge test ppl along batches:  105.41339499272401\n","\n","--------- TEST --------\n","Average test loss along batches:  5.051998154870395\n","Average test ppl along batches:  156.33453321068913\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a776f4cd02ad419e8ba1f10c4be53bfc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Epoch  0\n","\n","--------- TRAIN --------\n","Loss in the first batch:  9.208450317382812\n","ppl in the first batch:  9981.117304350353\n","\n","Loss in the last batch:  6.51194429397583\n","ppl in the last batch:  673.1339163166753\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.697106775809278\n","Averge test ppl along batches:  810.0587499261485\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.561234079874479\n","Average validation ppl along batches: :  707.1438283102283\n","\n","\n","Epoch  1\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.471914291381836\n","ppl in the first batch:  646.720554347008\n","\n","Loss in the last batch:  6.198537349700928\n","ppl in the last batch:  492.02884838436927\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.41963409470278\n","Averge test ppl along batches:  613.778488231992\n","\n","\n","Epoch  2\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.326158046722412\n","ppl in the first batch:  559.004792644673\n","\n","Loss in the last batch:  6.028243541717529\n","ppl in the last batch:  414.9854841709074\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.100461286315453\n","Averge test ppl along batches:  446.06348561372647\n","\n","\n","Epoch  3\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.889152526855469\n","ppl in the first batch:  361.09913284541085\n","\n","Loss in the last batch:  5.754105091094971\n","ppl in the last batch:  315.4830925284205\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.874358487092922\n","Averge test ppl along batches:  355.79633949904047\n","\n","\n","Epoch  4\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.95543909072876\n","ppl in the first batch:  385.8462950186212\n","\n","Loss in the last batch:  5.594949245452881\n","ppl in the last batch:  269.0639935245656\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.715435404029974\n","Averge test ppl along batches:  303.51632677561633\n","\n","\n","Epoch  5\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.697004318237305\n","ppl in the first batch:  297.9734290407671\n","\n","Loss in the last batch:  5.662175178527832\n","ppl in the last batch:  287.7739219182223\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.590162946390416\n","Averge test ppl along batches:  267.7792498210531\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.585988310667185\n","Average validation ppl along batches: :  266.6636991278098\n","\n","\n","Epoch  6\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.570838451385498\n","ppl in the first batch:  262.6542297458566\n","\n","Loss in the last batch:  5.5380167961120605\n","ppl in the last batch:  254.1734215656548\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.488256595269005\n","Averge test ppl along batches:  241.83522244909133\n","\n","\n","Epoch  7\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.475497245788574\n","ppl in the first batch:  238.76916437873945\n","\n","Loss in the last batch:  5.455568790435791\n","ppl in the last batch:  234.05796314599002\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.407316946003535\n","Averge test ppl along batches:  223.03237627323026\n","\n","\n","Epoch  8\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.355371952056885\n","ppl in the first batch:  211.74271984776158\n","\n","Loss in the last batch:  5.429863929748535\n","ppl in the last batch:  228.1182032108164\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.339731540854118\n","Averge test ppl along batches:  208.45674065810243\n","\n","\n","Epoch  9\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.265408039093018\n","ppl in the first batch:  193.5252585500063\n","\n","Loss in the last batch:  5.335134983062744\n","ppl in the last batch:  207.50075600521538\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.282013299439777\n","Averge test ppl along batches:  196.76562495938808\n","\n","\n","Epoch  10\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.391007423400879\n","ppl in the first batch:  219.42432744644364\n","\n","Loss in the last batch:  5.106916427612305\n","ppl in the last batch:  165.1602851645798\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.230718990802039\n","Averge test ppl along batches:  186.92715412042142\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.350511037386381\n","Average validation ppl along batches: :  210.71595408660008\n","\n","\n","Epoch  11\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.139491558074951\n","ppl in the first batch:  170.6289913298411\n","\n","Loss in the last batch:  5.146877765655518\n","ppl in the last batch:  171.8939583827203\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.185359362597879\n","Averge test ppl along batches:  178.6376339406552\n","\n","\n","Epoch  12\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.028397560119629\n","ppl in the first batch:  152.68814298394003\n","\n","Loss in the last batch:  5.032067775726318\n","ppl in the last batch:  153.24957104005748\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.14733556489059\n","Averge test ppl along batches:  171.9726693209105\n","\n","\n","Epoch  13\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.95718240737915\n","ppl in the first batch:  142.19259015248863\n","\n","Loss in the last batch:  4.81091833114624\n","ppl in the last batch:  122.84437755186113\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.107966568916356\n","Averge test ppl along batches:  165.3338179028204\n","\n","\n","Epoch  14\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.9174299240112305\n","ppl in the first batch:  136.6509581435761\n","\n","Loss in the last batch:  5.137808322906494\n","ppl in the last batch:  170.34202419521782\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.075338204701741\n","Averge test ppl along batches:  160.02630447689654\n","\n","\n","Epoch  15\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.096778392791748\n","ppl in the first batch:  163.49434339915376\n","\n","Loss in the last batch:  5.136961936950684\n","ppl in the last batch:  170.19791009493315\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.044507419319094\n","Averge test ppl along batches:  155.16784768656896\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.245388228159684\n","Average validation ppl along batches: :  189.68944371991515\n","\n","\n","Epoch  16\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.968051910400391\n","ppl in the first batch:  143.7465832070288\n","\n","Loss in the last batch:  5.216266632080078\n","ppl in the last batch:  184.24504392786594\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.016893287409023\n","Averge test ppl along batches:  150.94164231949895\n","\n","\n","Epoch  17\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.671447277069092\n","ppl in the first batch:  106.85227542745335\n","\n","Loss in the last batch:  5.0617828369140625\n","ppl in the last batch:  157.87172511339477\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.989499832397183\n","Averge test ppl along batches:  146.862949033293\n","\n","\n","Epoch  18\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.822023391723633\n","ppl in the first batch:  124.21617465337921\n","\n","Loss in the last batch:  4.669163227081299\n","ppl in the last batch:  106.60849799496835\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.9656757502795354\n","Averge test ppl along batches:  143.40542379371885\n","\n","\n","Epoch  19\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.0095720291137695\n","ppl in the first batch:  149.8405950125154\n","\n","Loss in the last batch:  4.951361656188965\n","ppl in the last batch:  141.36732662103586\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.941516649051707\n","Averge test ppl along batches:  139.98239280921905\n","\n","\n","Epoch  20\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.772921085357666\n","ppl in the first batch:  118.26419770905711\n","\n","Loss in the last batch:  4.833968639373779\n","ppl in the last batch:  125.70886515143981\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.920148750781287\n","Averge test ppl along batches:  137.02299394800838\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.19523129096398\n","Average validation ppl along batches: :  180.40986514344337\n","\n","\n","Epoch  21\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.632207870483398\n","ppl in the first batch:  102.74065193301338\n","\n","Loss in the last batch:  4.757559776306152\n","ppl in the last batch:  116.4613870348851\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.89989469621098\n","Averge test ppl along batches:  134.27563920684406\n","\n","\n","Epoch  22\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.687443256378174\n","ppl in the first batch:  108.57522561444698\n","\n","Loss in the last batch:  4.997037887573242\n","ppl in the last batch:  147.97419309400024\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.880392052085795\n","Averge test ppl along batches:  131.6822800796183\n","\n","\n","Epoch  23\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.717338562011719\n","ppl in the first batch:  111.87012072489779\n","\n","Loss in the last batch:  4.952322006225586\n","ppl in the last batch:  141.50315394878382\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.8608629765212985\n","Averge test ppl along batches:  129.13559502229813\n","\n","\n","Epoch  24\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.053882598876953\n","ppl in the first batch:  156.6294146413249\n","\n","Loss in the last batch:  5.042320251464844\n","ppl in the last batch:  154.82884042612935\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.843560112847222\n","Averge test ppl along batches:  126.92039930773045\n","\n","\n","Epoch  25\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.744487285614014\n","ppl in the first batch:  114.94885446054242\n","\n","Loss in the last batch:  4.826647758483887\n","ppl in the last batch:  124.79192601924602\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.828841768261867\n","Averge test ppl along batches:  125.06602129905671\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.178183372204121\n","Average validation ppl along batches: :  177.36032047137556\n","\n","\n","Epoch  26\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.624964237213135\n","ppl in the first batch:  101.99912524449509\n","\n","Loss in the last batch:  4.882153511047363\n","ppl in the last batch:  131.91443741973097\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.81183652863292\n","Averge test ppl along batches:  122.95722475066083\n","\n","\n","Epoch  27\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.8265886306762695\n","ppl in the first batch:  124.78454756439025\n","\n","Loss in the last batch:  4.904465198516846\n","ppl in the last batch:  134.8907509394761\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.798317617477347\n","Averge test ppl along batches:  121.30616238179458\n","\n","\n","Epoch  28\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.6506876945495605\n","ppl in the first batch:  104.65693283769545\n","\n","Loss in the last batch:  5.01612663269043\n","ppl in the last batch:  150.82596654453758\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.78276753679621\n","Averge test ppl along batches:  119.43443226281148\n","\n","\n","Epoch  29\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.817173004150391\n","ppl in the first batch:  123.61513687487783\n","\n","Loss in the last batch:  4.772505760192871\n","ppl in the last batch:  118.21508981023325\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.742962422073341\n","Averge test ppl along batches:  114.77370671547672\n","\n","\n","Epoch  30\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.941654205322266\n","ppl in the first batch:  140.0016495895329\n","\n","Loss in the last batch:  4.933480739593506\n","ppl in the last batch:  138.86201463276143\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.734545725847125\n","Averge test ppl along batches:  113.81174523889533\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.162391259120061\n","Average validation ppl along batches: :  174.58142629175487\n","\n","\n","Epoch  31\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.561952590942383\n","ppl in the first batch:  95.77029759700841\n","\n","Loss in the last batch:  4.809802055358887\n","ppl in the last batch:  122.70732585556392\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.7310046039215505\n","Averge test ppl along batches:  113.40943670462478\n","\n","\n","Epoch  32\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.736600875854492\n","ppl in the first batch:  114.04588596270608\n","\n","Loss in the last batch:  4.789228916168213\n","ppl in the last batch:  120.20864197751584\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.7280616397364135\n","Averge test ppl along batches:  113.07616743444768\n","\n","\n","Epoch  33\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.58317756652832\n","ppl in the first batch:  97.8247455019262\n","\n","Loss in the last batch:  4.545183181762695\n","ppl in the last batch:  94.17767726233849\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.726100319233841\n","Averge test ppl along batches:  112.85460617625006\n","\n","\n","Epoch  34\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.596354007720947\n","ppl in the first batch:  99.12225702775059\n","\n","Loss in the last batch:  4.602748394012451\n","ppl in the last batch:  99.75811381966466\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.7227126307320555\n","Averge test ppl along batches:  112.472936778066\n","\n","\n","Epoch  35\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.660114288330078\n","ppl in the first batch:  105.64815581801133\n","\n","Loss in the last batch:  4.575272560119629\n","ppl in the last batch:  97.05448871527423\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.721957184952688\n","Averge test ppl along batches:  112.38800165866199\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.161076366901398\n","Average validation ppl along batches: :  174.352021387215\n","\n","\n","Epoch  36\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.765157699584961\n","ppl in the first batch:  117.34962181534779\n","\n","Loss in the last batch:  4.693693161010742\n","ppl in the last batch:  109.25593538980301\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.71492540310144\n","Averge test ppl along batches:  111.60048581306944\n","\n","\n","Epoch  37\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.755034446716309\n","ppl in the first batch:  116.16765468972437\n","\n","Loss in the last batch:  4.795982837677002\n","ppl in the last batch:  121.02326957891773\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.7138926754259085\n","Averge test ppl along batches:  111.48529239472116\n","\n","\n","Epoch  38\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.857863426208496\n","ppl in the first batch:  128.74882666342026\n","\n","Loss in the last batch:  4.8339009284973145\n","ppl in the last batch:  125.70035358216717\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.7144257467087005\n","Averge test ppl along batches:  111.5447378454741\n","\n","\n","Epoch  39\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.687258243560791\n","ppl in the first batch:  108.5551396641945\n","\n","Loss in the last batch:  4.887696743011475\n","ppl in the last batch:  132.64770019097446\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.71415961278628\n","Averge test ppl along batches:  111.51505595671983\n","\n","--------- TEST --------\n","Average test loss along batches:  5.078428782265762\n","Average test ppl along batches:  160.521643230309\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f22bb5490f7a4a7ebb259844e34fdb36"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Epoch  0\n","\n","--------- TRAIN --------\n","Loss in the first batch:  9.207806587219238\n","ppl in the first batch:  9974.69422566192\n","\n","Loss in the last batch:  6.81000280380249\n","ppl in the last batch:  906.8733496377636\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.706436116582908\n","Averge test ppl along batches:  817.6514263135903\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.582949161529541\n","Average validation ppl along batches: :  722.6674526669044\n","\n","\n","Epoch  1\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.627122402191162\n","ppl in the first batch:  755.3055747930135\n","\n","Loss in the last batch:  6.161583423614502\n","ppl in the last batch:  474.1783058382899\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.4666731499101475\n","Averge test ppl along batches:  643.3398674968823\n","\n","\n","Epoch  2\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.332119941711426\n","ppl in the first batch:  562.3474749762244\n","\n","Loss in the last batch:  6.109443664550781\n","ppl in the last batch:  450.0882454552676\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.111437518121264\n","Averge test ppl along batches:  450.9865507575205\n","\n","\n","Epoch  3\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.9518866539001465\n","ppl in the first batch:  384.47803220255673\n","\n","Loss in the last batch:  5.746208190917969\n","ppl in the last batch:  313.0015651221694\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.871459101614524\n","Averge test ppl along batches:  354.76624280434856\n","\n","\n","Epoch  4\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.8114118576049805\n","ppl in the first batch:  334.0904810393489\n","\n","Loss in the last batch:  5.798041820526123\n","ppl in the last batch:  329.6534069394156\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.703318645239239\n","Averge test ppl along batches:  299.86088344058186\n","\n","\n","Epoch  5\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.5623555183410645\n","ppl in the first batch:  260.4355751548019\n","\n","Loss in the last batch:  5.419977188110352\n","ppl in the last batch:  225.8739698311882\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.574090878531631\n","Averge test ppl along batches:  263.5098842153615\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.577215955807612\n","Average validation ppl along batches: :  264.33466104093884\n","\n","\n","Epoch  6\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.558813571929932\n","ppl in the first batch:  259.51475800920997\n","\n","Loss in the last batch:  5.35156774520874\n","ppl in the last batch:  210.93873697105707\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.473150799807892\n","Averge test ppl along batches:  238.2095622275366\n","\n","\n","Epoch  7\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.3263139724731445\n","ppl in the first batch:  205.67843879507535\n","\n","Loss in the last batch:  5.554490089416504\n","ppl in the last batch:  258.39517248917707\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.39193514601825\n","Averge test ppl along batches:  219.62798681291048\n","\n","\n","Epoch  8\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.340663433074951\n","ppl in the first batch:  208.6510904155506\n","\n","Loss in the last batch:  5.3321075439453125\n","ppl in the last batch:  206.87351005313363\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.323883248246424\n","Averge test ppl along batches:  205.17909835629243\n","\n","\n","Epoch  9\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.228824138641357\n","ppl in the first batch:  186.57329016436512\n","\n","Loss in the last batch:  5.300660133361816\n","ppl in the last batch:  200.46910264725506\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.264370267249678\n","Averge test ppl along batches:  193.32452766015598\n","\n","\n","Epoch  10\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.315756320953369\n","ppl in the first batch:  203.51838015039039\n","\n","Loss in the last batch:  5.358308792114258\n","ppl in the last batch:  212.36548838744815\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.212860659014326\n","Averge test ppl along batches:  183.6185777398487\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.332782823305863\n","Average validation ppl along batches: :  207.01325464272546\n","\n","\n","Epoch  11\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.143243312835693\n","ppl in the first batch:  171.27035182172514\n","\n","Loss in the last batch:  5.115789890289307\n","ppl in the last batch:  166.63235028919706\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.167206866556107\n","Averge test ppl along batches:  175.4241694378758\n","\n","\n","Epoch  12\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.0053486824035645\n","ppl in the first batch:  149.20910067692188\n","\n","Loss in the last batch:  5.216800212860107\n","ppl in the last batch:  184.3433797748474\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.125054995218913\n","Averge test ppl along batches:  168.18339067990493\n","\n","\n","Epoch  13\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.196587562561035\n","ppl in the first batch:  180.65471592391253\n","\n","Loss in the last batch:  4.947528839111328\n","ppl in the last batch:  140.82652856939555\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.086743491969696\n","Averge test ppl along batches:  161.8618982893719\n","\n","\n","Epoch  14\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.967004299163818\n","ppl in the first batch:  143.59607152387292\n","\n","Loss in the last batch:  4.9803924560546875\n","ppl in the last batch:  145.53148516006735\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.053588462202517\n","Averge test ppl along batches:  156.58335096102434\n","\n","\n","Epoch  15\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.074653625488281\n","ppl in the first batch:  159.91679128474925\n","\n","Loss in the last batch:  5.054080486297607\n","ppl in the last batch:  156.66041269914854\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.023334160605885\n","Averge test ppl along batches:  151.91697592605234\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.232270039044893\n","Average validation ppl along batches: :  187.21731212071924\n","\n","\n","Epoch  16\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.966458320617676\n","ppl in the first batch:  143.51769254807718\n","\n","Loss in the last batch:  5.135842323303223\n","ppl in the last batch:  170.00746082671603\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.99296512560213\n","Averge test ppl along batches:  147.372755016084\n","\n","\n","Epoch  17\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.907447814941406\n","ppl in the first batch:  135.29367889982183\n","\n","Loss in the last batch:  5.020052433013916\n","ppl in the last batch:  151.41924295318685\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.967505623397943\n","Averge test ppl along batches:  143.668077762181\n","\n","\n","Epoch  18\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.868015289306641\n","ppl in the first batch:  130.06252408143664\n","\n","Loss in the last batch:  5.11583137512207\n","ppl in the last batch:  166.63926314777024\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.941994611168198\n","Averge test ppl along batches:  140.04931508183918\n","\n","\n","Epoch  19\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.7842488288879395\n","ppl in the first batch:  119.61148064060986\n","\n","Loss in the last batch:  4.85954475402832\n","ppl in the last batch:  128.96547772715263\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.918924981237728\n","Averge test ppl along batches:  136.85541194303877\n","\n","\n","Epoch  20\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.952359676361084\n","ppl in the first batch:  141.50848449216699\n","\n","Loss in the last batch:  4.78007173538208\n","ppl in the last batch:  119.11289434733246\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.896876049186904\n","Averge test ppl along batches:  133.8709196082771\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.175942453054281\n","Average validation ppl along batches: :  176.96331532716204\n","\n","\n","Epoch  21\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.939507961273193\n","ppl in the first batch:  139.70149410092543\n","\n","Loss in the last batch:  4.883900165557861\n","ppl in the last batch:  132.14504770646985\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.877212674650427\n","Averge test ppl along batches:  131.26427725618078\n","\n","\n","Epoch  22\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.780052185058594\n","ppl in the first batch:  119.1105656744798\n","\n","Loss in the last batch:  4.954634189605713\n","ppl in the last batch:  141.8307137327909\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.858226095341838\n","Averge test ppl along batches:  128.7955283569245\n","\n","\n","Epoch  23\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.679294586181641\n","ppl in the first batch:  107.69407688035967\n","\n","Loss in the last batch:  4.889082431793213\n","ppl in the last batch:  132.8316360305354\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.838605802353114\n","Averge test ppl along batches:  126.29315131517275\n","\n","\n","Epoch  24\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.99475622177124\n","ppl in the first batch:  147.63695032199587\n","\n","Loss in the last batch:  4.859048366546631\n","ppl in the last batch:  128.90147676439128\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.823964945620416\n","Averge test ppl along batches:  124.4575813275209\n","\n","\n","Epoch  25\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.707345962524414\n","ppl in the first batch:  110.7578140867607\n","\n","Loss in the last batch:  4.56037712097168\n","ppl in the last batch:  95.61953316266293\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.8061410012673385\n","Averge test ppl along batches:  122.25890903814549\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.154622972011566\n","Average validation ppl along batches: :  173.2304817049195\n","\n","\n","Epoch  26\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.016544342041016\n","ppl in the first batch:  150.8889811210471\n","\n","Loss in the last batch:  4.5615010261535645\n","ppl in the last batch:  95.72706086562638\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.789747334687859\n","Averge test ppl along batches:  120.27097652003303\n","\n","\n","Epoch  27\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.785349369049072\n","ppl in the first batch:  119.74319034140129\n","\n","Loss in the last batch:  5.074474811553955\n","ppl in the last batch:  159.888198490606\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.776169874896742\n","Averge test ppl along batches:  118.6490379914761\n","\n","\n","Epoch  28\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.475207805633545\n","ppl in the first batch:  87.81284651807117\n","\n","Loss in the last batch:  4.75266170501709\n","ppl in the last batch:  115.89234559918488\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.7611002268856515\n","Averge test ppl along batches:  116.8744435918005\n","\n","\n","Epoch  29\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.406230449676514\n","ppl in the first batch:  81.95992839205586\n","\n","Loss in the last batch:  4.6946940422058105\n","ppl in the last batch:  109.36534234353225\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.719960777364002\n","Averge test ppl along batches:  112.16385321954382\n","\n","\n","Epoch  30\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.7419819831848145\n","ppl in the first batch:  114.66123325571914\n","\n","Loss in the last batch:  4.73092794418335\n","ppl in the last batch:  113.40074310012646\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.714061576663268\n","Averge test ppl along batches:  111.50412398884905\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.148522885946127\n","Average validation ppl along batches: :  172.17697735778745\n","\n","\n","Epoch  31\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.751049041748047\n","ppl in the first batch:  115.70560088891328\n","\n","Loss in the last batch:  4.8132524490356445\n","ppl in the last batch:  123.13144570624351\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.7082222128567635\n","Averge test ppl along batches:  110.85490819132269\n","\n","\n","Epoch  32\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.616115570068359\n","ppl in the first batch:  101.10055039413767\n","\n","Loss in the last batch:  4.716754913330078\n","ppl in the last batch:  111.80484692675778\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.706171566311446\n","Averge test ppl along batches:  110.62781687839627\n","\n","\n","Epoch  33\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.768592357635498\n","ppl in the first batch:  117.75337061125502\n","\n","Loss in the last batch:  4.7280120849609375\n","ppl in the last batch:  113.0705641091957\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.702375788666886\n","Averge test ppl along batches:  110.20869423562566\n","\n","\n","Epoch  34\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.8593058586120605\n","ppl in the first batch:  128.9346721454705\n","\n","Loss in the last batch:  4.934217929840088\n","ppl in the last batch:  138.9644200970865\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.700563673922279\n","Averge test ppl along batches:  110.00916427600892\n","\n","\n","Epoch  35\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.844945907592773\n","ppl in the first batch:  127.09640685719549\n","\n","Loss in the last batch:  4.557719707489014\n","ppl in the last batch:  95.36576985238776\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.698380557369424\n","Averge test ppl along batches:  109.76926340956908\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.139604275043194\n","Average validation ppl along batches: :  170.6482251964093\n","\n","\n","Epoch  36\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.762344837188721\n","ppl in the first batch:  117.0199972884864\n","\n","Loss in the last batch:  4.786543369293213\n","ppl in the last batch:  119.88624912902095\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.692585612722365\n","Averge test ppl along batches:  109.13499615095309\n","\n","\n","Epoch  37\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.461187362670898\n","ppl in the first batch:  86.59026212661358\n","\n","Loss in the last batch:  4.57979679107666\n","ppl in the last batch:  97.49458042523386\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.691841470959343\n","Averge test ppl along batches:  109.05381445160255\n","\n","\n","Epoch  38\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.4621992111206055\n","ppl in the first batch:  86.67792269123014\n","\n","Loss in the last batch:  4.5406174659729\n","ppl in the last batch:  93.74866886467348\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.692590532056092\n","Averge test ppl along batches:  109.13553302374098\n","\n","\n","Epoch  39\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.877740859985352\n","ppl in the first batch:  131.33362743568858\n","\n","Loss in the last batch:  4.653288841247559\n","ppl in the last batch:  104.92951523267695\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.692306540328074\n","Averge test ppl along batches:  109.10454383567426\n","\n","--------- TEST --------\n","Average test loss along batches:  5.057710561259039\n","Average test ppl along batches:  157.23013518277298\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch:   0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"825e714725df4b26997fe2ac67dbc149"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Epoch  0\n","\n","--------- TRAIN --------\n","Loss in the first batch:  9.2086181640625\n","ppl in the first batch:  9982.792742353879\n","\n","Loss in the last batch:  6.734975337982178\n","ppl in the last batch:  841.3227351149862\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.716543628744883\n","Averge test ppl along batches:  825.9577554952479\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  6.606441928790166\n","Average validation ppl along batches: :  739.8459055642542\n","\n","\n","Epoch  1\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.6254167556762695\n","ppl in the first batch:  754.0183885261341\n","\n","Loss in the last batch:  6.190847873687744\n","ppl in the last batch:  488.2599134949303\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.492888264097217\n","Averge test ppl along batches:  660.4281019725355\n","\n","\n","Epoch  2\n","\n","--------- TRAIN --------\n","Loss in the first batch:  6.34196662902832\n","ppl in the first batch:  567.912086258718\n","\n","Loss in the last batch:  5.928519248962402\n","ppl in the last batch:  375.597934817265\n","\n","lr:  0.001\n","\n","Average test loss along batches:  6.142163267237229\n","Averge test ppl along batches:  465.0585293504138\n","\n","\n","Epoch  3\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.825043201446533\n","ppl in the first batch:  338.675764044798\n","\n","Loss in the last batch:  6.010805606842041\n","ppl in the last batch:  407.81172388907015\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.887815008787623\n","Averge test ppl along batches:  360.616479081965\n","\n","\n","Epoch  4\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.621614933013916\n","ppl in the first batch:  276.3352860626461\n","\n","Loss in the last batch:  5.708003997802734\n","ppl in the last batch:  301.26913389822744\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.718386409126642\n","Averge test ppl along batches:  304.4133278793114\n","\n","\n","Epoch  5\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.470345973968506\n","ppl in the first batch:  237.54236201981115\n","\n","Loss in the last batch:  5.572216510772705\n","ppl in the last batch:  263.0164323838001\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.594782635501531\n","Averge test ppl along batches:  269.01916851994406\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.582015725282522\n","Average validation ppl along batches: :  265.6064561983399\n","\n","\n","Epoch  6\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.406204700469971\n","ppl in the first batch:  222.7844474133229\n","\n","Loss in the last batch:  5.429696083068848\n","ppl in the last batch:  228.07991754098236\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.496392445295732\n","Averge test ppl along batches:  243.81078308545588\n","\n","\n","Epoch  7\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.377842903137207\n","ppl in the first batch:  216.55464190220204\n","\n","Loss in the last batch:  5.3311614990234375\n","ppl in the last batch:  206.6778909662892\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.41300976621143\n","Averge test ppl along batches:  224.30568039883232\n","\n","\n","Epoch  8\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.511117935180664\n","ppl in the first batch:  247.42758050723424\n","\n","Loss in the last batch:  5.343238830566406\n","ppl in the last batch:  209.18914246194794\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.343218635750688\n","Averge test ppl along batches:  209.1849179684222\n","\n","\n","Epoch  9\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.4352216720581055\n","ppl in the first batch:  229.34368172730433\n","\n","Loss in the last batch:  5.347031593322754\n","ppl in the last batch:  209.9840537525758\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.284579211718415\n","Averge test ppl along batches:  197.27115659003005\n","\n","\n","Epoch  10\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.234180927276611\n","ppl in the first batch:  187.57540550848023\n","\n","Loss in the last batch:  5.076075077056885\n","ppl in the last batch:  160.14426689304543\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.230853799997036\n","Averge test ppl along batches:  186.95235531822996\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.333033139889057\n","Average validation ppl along batches: :  207.06507997940344\n","\n","\n","Epoch  11\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.15484619140625\n","ppl in the first batch:  173.26915442427637\n","\n","Loss in the last batch:  5.189450740814209\n","ppl in the last batch:  179.37000524716203\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.184717538331379\n","Averge test ppl along batches:  178.523016758261\n","\n","\n","Epoch  12\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.072933197021484\n","ppl in the first batch:  159.64190241582483\n","\n","Loss in the last batch:  5.231876373291016\n","ppl in the last batch:  187.14362558128946\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.143864670844927\n","Averge test ppl along batches:  171.37680509594608\n","\n","\n","Epoch  13\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.246685981750488\n","ppl in the first batch:  189.93577367986364\n","\n","Loss in the last batch:  5.148706436157227\n","ppl in the last batch:  172.20858337888515\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.1077030797345815\n","Averge test ppl along batches:  165.2902599691957\n","\n","\n","Epoch  14\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.183126926422119\n","ppl in the first batch:  178.23928163778118\n","\n","Loss in the last batch:  5.0570759773254395\n","ppl in the last batch:  157.13039111644645\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.071717638221869\n","Averge test ppl along batches:  159.44796619087802\n","\n","\n","Epoch  15\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.12522554397583\n","ppl in the first batch:  168.21207659422348\n","\n","Loss in the last batch:  5.221709728240967\n","ppl in the last batch:  185.2506417191102\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.040028476279621\n","Averge test ppl along batches:  154.47441381986206\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.235291586472438\n","Average validation ppl along batches: :  187.78385359348252\n","\n","\n","Epoch  16\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.05118989944458\n","ppl in the first batch:  156.20822602708873\n","\n","Loss in the last batch:  4.767833232879639\n","ppl in the last batch:  117.66401503284504\n","\n","lr:  0.001\n","\n","Average test loss along batches:  5.011308845682594\n","Averge test ppl along batches:  150.10106677097173\n","\n","\n","Epoch  17\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.426796913146973\n","ppl in the first batch:  83.66300739119333\n","\n","Loss in the last batch:  5.177988052368164\n","ppl in the last batch:  177.3256818655894\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.982621378731691\n","Averge test ppl along batches:  145.85622536351542\n","\n","\n","Epoch  18\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.924344062805176\n","ppl in the first batch:  137.59905569653654\n","\n","Loss in the last batch:  4.889447212219238\n","ppl in the last batch:  132.88009924999582\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.9597762062850785\n","Averge test ppl along batches:  142.5618878722214\n","\n","\n","Epoch  19\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.959648132324219\n","ppl in the first batch:  142.54363057574108\n","\n","Loss in the last batch:  5.048630237579346\n","ppl in the last batch:  155.80889707945994\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.935429593380909\n","Averge test ppl along batches:  139.13290026841742\n","\n","\n","Epoch  20\n","\n","--------- TRAIN --------\n","Loss in the first batch:  5.0002899169921875\n","ppl in the first batch:  148.45619283706867\n","\n","Loss in the last batch:  5.0870466232299805\n","ppl in the last batch:  161.9109711279723\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.912534641167163\n","Averge test ppl along batches:  135.9836477217871\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.186091147936308\n","Average validation ppl along batches: :  178.7684061848343\n","\n","\n","Epoch  21\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.837506294250488\n","ppl in the first batch:  126.15436728306103\n","\n","Loss in the last batch:  4.723978042602539\n","ppl in the last batch:  112.6153514549808\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.8913806968990885\n","Averge test ppl along batches:  133.1372694233315\n","\n","\n","Epoch  22\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.975397109985352\n","ppl in the first batch:  144.8063177667061\n","\n","Loss in the last batch:  5.083191871643066\n","ppl in the last batch:  161.2880459373541\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.872623124986298\n","Averge test ppl along batches:  130.66321369717997\n","\n","\n","Epoch  23\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.691874027252197\n","ppl in the first batch:  109.0573648973171\n","\n","Loss in the last batch:  4.955288410186768\n","ppl in the last batch:  141.9235326634574\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.854978643414455\n","Averge test ppl along batches:  128.3779494707831\n","\n","\n","Epoch  24\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.93726921081543\n","ppl in the first batch:  139.38908714814303\n","\n","Loss in the last batch:  4.913317680358887\n","ppl in the last batch:  136.09016994748274\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.836228454856931\n","Averge test ppl along batches:  125.99326521608283\n","\n","\n","Epoch  25\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.468500137329102\n","ppl in the first batch:  87.22579813475417\n","\n","Loss in the last batch:  5.01688814163208\n","ppl in the last batch:  150.94086560947454\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.819990603709693\n","Averge test ppl along batches:  123.96392597331541\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.165345531243545\n","Average validation ppl along batches: :  175.09794993275057\n","\n","\n","Epoch  26\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.981564044952393\n","ppl in the first batch:  145.70208815111812\n","\n","Loss in the last batch:  4.927201271057129\n","ppl in the last batch:  137.99276704374563\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.804876432752682\n","Averge test ppl along batches:  122.10440198410727\n","\n","\n","Epoch  27\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.879541397094727\n","ppl in the first batch:  131.5703115208918\n","\n","Loss in the last batch:  4.963112831115723\n","ppl in the last batch:  143.03835786595792\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.788243908497478\n","Averge test ppl along batches:  120.09029383956002\n","\n","\n","Epoch  28\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.680113315582275\n","ppl in the first batch:  107.78228529185847\n","\n","Loss in the last batch:  4.945364952087402\n","ppl in the last batch:  140.52212533747982\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.774052799201629\n","Averge test ppl along batches:  118.3981147024141\n","\n","\n","Epoch  29\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.7822794914245605\n","ppl in the first batch:  119.37615706255764\n","\n","Loss in the last batch:  4.704174041748047\n","ppl in the last batch:  110.4070556581715\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.760928204796267\n","Averge test ppl along batches:  116.85434033496988\n","\n","\n","Epoch  30\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.506297588348389\n","ppl in the first batch:  90.58581091334035\n","\n","Loss in the last batch:  4.497843265533447\n","ppl in the last batch:  89.8231974579407\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.747594551771562\n","Averge test ppl along batches:  115.3065866425796\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.15101564847506\n","Average validation ppl along batches: :  172.6067090623107\n","\n","\n","Epoch  31\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.966736793518066\n","ppl in the first batch:  143.55766390138945\n","\n","Loss in the last batch:  4.64793586730957\n","ppl in the last batch:  104.36933093592268\n","\n","lr:  0.001\n","\n","Average test loss along batches:  4.736066371157108\n","Averge test ppl along batches:  113.98494418922465\n","\n","\n","Epoch  32\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.760887622833252\n","ppl in the first batch:  116.84959825267443\n","\n","Loss in the last batch:  4.569207668304443\n","ppl in the last batch:  96.46764511134009\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.694881178654129\n","Averge test ppl along batches:  109.38581050037695\n","\n","\n","Epoch  33\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.798860549926758\n","ppl in the first batch:  121.37204131595236\n","\n","Loss in the last batch:  4.921994209289551\n","ppl in the last batch:  137.276097672395\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.68759140249801\n","Averge test ppl along batches:  108.59131180435602\n","\n","\n","Epoch  34\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.56722354888916\n","ppl in the first batch:  96.27643154173566\n","\n","Loss in the last batch:  4.5972161293029785\n","ppl in the last batch:  99.20774931187027\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.682672903417997\n","Averge test ppl along batches:  108.05851688690231\n","\n","\n","Epoch  35\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.828824043273926\n","ppl in the first batch:  125.06380452498351\n","\n","Loss in the last batch:  4.609188079833984\n","ppl in the last batch:  100.40259764026978\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.682346239481887\n","Averge test ppl along batches:  108.02322383124391\n","\n","--------- VALIDATION --------\n","Average validation loss along batches:  5.1393104791641235\n","Average validation ppl along batches: :  170.59809681519243\n","\n","\n","Epoch  36\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.595439910888672\n","ppl in the first batch:  99.03169108592\n","\n","Loss in the last batch:  4.880795955657959\n","ppl in the last batch:  131.73547776557766\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.679542897861661\n","Averge test ppl along batches:  107.72082189793079\n","\n","\n","Epoch  37\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.438745498657227\n","ppl in the first batch:  84.66865807606156\n","\n","Loss in the last batch:  4.633871078491211\n","ppl in the last batch:  102.91167319057467\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.6758802782636435\n","Averge test ppl along batches:  107.32700314891626\n","\n","\n","Epoch  38\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.792497158050537\n","ppl in the first batch:  120.60215559441295\n","\n","Loss in the last batch:  4.651973247528076\n","ppl in the last batch:  104.7915613869524\n","\n","lr:  0.0001\n","\n","Average test loss along batches:  4.6730445276838095\n","Averge test ppl along batches:  107.0230816639334\n","\n","\n","Epoch  39\n","\n","--------- TRAIN --------\n","Loss in the first batch:  4.546324253082275\n","ppl in the first batch:  94.28520204386255\n","\n","Loss in the last batch:  4.457784652709961\n","ppl in the last batch:  86.2961213009214\n","\n","lr:  1e-05\n","\n","Average test loss along batches:  4.667668858619585\n","Averge test ppl along batches:  106.44930459423773\n","\n","--------- TEST --------\n","Average test loss along batches:  5.062279853327521\n","Average test ppl along batches:  157.95020945438432\n","\n","\n","Final average loss along runs:  5.0649191165792535 +/- 0.009941051270663876\n","Final average ppl along runs:  158.3676322398059\n"]}],"source":["lossTs = [] # list that contains the losses computed on the test set in every run\n","lrs = [] # list containing the used learning rates\n","\n","for run in tqdm(range(0, RUNS), desc = 'Run: '):\n","  # Instantiation of the model\n","  net = ImprovedNetwork(HD_SIZE, EMB_DIM, len(trainCorpus.word2id), padding_idx = PAD_TOKEN).to(device)\n","  net.apply(init_weights)\n","  net.hidden = net.init_hidden()\n","\n","  # Cost function\n","  cost_function = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN) # the padding doesn't contribute to the input gradient\n","\n","  # Optimizer with weight decay\n","  optimizer = optim.Adam(net.parameters(), lr = LEARNING_RATE_I, weight_decay = 0.00000000001)\n","\n","  # Definition of the adaptive learning rate. The lr is reduced by a 0.01 factor if for 5 epochs \n","  # no improvement (in the order of 0.1) is observed in the loss value\n","  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.1, patience = 5, threshold = 0.1, threshold_mode = \"abs\")\n","\n","  # Training\n","  sampled_epochs = [] # list containing the number of the epochs in which a test on the valid set is performed\n","  losses_train = [] # list that contains the means of the losses for each training step in one run\n","  losses_eval = [] # list that contains the means of the losses for each evaluation step (test step on the validation set) in the sampled epochs\n","\n","  for epoch in tqdm(range(EPOCHS_I), desc = 'Epoch: '):\n","    print(\"\\n\\nEpoch \", epoch)\n","    print(\"\\n--------- TRAIN --------\")\n","    loss = training_step(net, train_loader, optimizer, cost_function)\n","    losses_train.append(np.asarray(loss).mean())\n","\n","    lrs.append(optimizer.param_groups[0]['lr'])\n","    print(\"\\nlr: \", lrs[-1])\n","    scheduler.step(np.asarray(loss).mean())\n","    \n","    print(\"\\nAverage test loss along batches: \", sum(loss)/len(loss))\n","    print(\"Averge test ppl along batches: \", np.exp(sum(loss)/len(loss)))\n","\n","    if epoch % 5 == 0:\n","      sampled_epochs.append(epoch)\n","\n","      # Compute the loss on the valid set\n","      print(\"\\n--------- VALIDATION --------\")\n","      lossV = test_step(net, valid_loader, cost_function)\n","      losses_eval.append(np.asarray(lossV).mean())\n","      print(\"Average validation loss along batches: \", sum(lossV)/len(lossV))\n","      print(\"Average validation ppl along batches: : \", np.exp(sum(lossV)/len(lossV)))\n","\n","  # Print the losses along epochs in a file\n","  loss_to_file(losses_train, \"train\"+str(run))\n","  loss_to_file(sampled_epochs, \"s_epochs\"+str(run))\n","  loss_to_file(losses_eval, \"eval\"+str(run))\n","\n","  # Testing\n","  print(\"\\n--------- TEST --------\")\n","  if run == RUNS - 1:\n","    lossT = test_step(net, test_loader, cost_function, True)\n","    print(\"Average test loss along batches: \", sum(lossT)/len(lossT))\n","    print(\"Average test ppl along batches: \", np.exp(sum(lossT)/len(lossT)))\n","    lossTs.append(np.asarray(lossT).mean())\n","  else:\n","    lossT = test_step(net, test_loader, cost_function)\n","    print(\"Average test loss along batches: \", sum(lossT)/len(lossT))\n","    print(\"Average test ppl along batches: \", np.exp(sum(lossT)/len(lossT)))\n","    lossTs.append(np.asarray(lossT).mean())\n","\n","lossTs = np.asarray(lossTs)\n","print('\\n\\nFinal average loss along runs: ', lossTs.mean(), \"+/-\", lossTs.std())\n","print('Final average ppl along runs: ', np.exp(lossTs.mean()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFtI55wz_h1T"},"outputs":[],"source":["# Save the model\n","torch.save(net, path.join(SAVE, \"Network\"))"]},{"cell_type":"markdown","source":["</br>\n","\n","---"],"metadata":{"id":"GE13sAWiv_lq"}},{"cell_type":"markdown","source":["# Statistics\n","\n","In this section some statistic about the obtained results are computed."],"metadata":{"id":"DeYFl0NPwAZT"}},{"cell_type":"markdown","source":["#### Definition of the functions"],"metadata":{"id":"8lAb-Lo6w4T4"}},{"cell_type":"code","source":["\"\"\"\n","Function that load the item from the specified .txt file organized by sentences.\n",":param source: path of the .txt file in which the sentences are contained\n",":return sents: list of the words contained in the specified file\n","\"\"\"\n","def read_words(source):\n","  with open(source, 'r') as f:\n","    sents = []\n","    for line in f:\n","      for word in line.split():\n","        sents.append(word)\n","  f.close()\n","\n","  return sents"],"metadata":{"id":"0rKfN-GlwIkV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Function that load the losses from the specified .txt file organized with one loss per row.\n",":param source: path of the .txt file in which the losses are contained\n",":return sents: list of the losses contained in the specified file\n","\"\"\"\n","def read_losses(source):\n","  with open(source, 'r') as f:\n","    losses = []\n","    for line in f:\n","      losses.append(float(line[:-1])) # exclude the '\\n' character\n","  f.close()\n","\n","  return losses"],"metadata":{"id":"p3jXV9GVwQSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Function that displays the loss plot over epochs.\n",":param n_epochs: integer number of epochs performed\n",":param losses: list containing all the losses over n_epochs\n","\"\"\"\n","def lossPlot(n_epochs, losses):\n","  fig = plt.figure(figsize = (15, 10))\n","  plt.plot(n_epochs, losses, 'royalblue', label = \"Loss\")\n","  plt.title(\"Loss over epochs\")\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(\"Loss\")\n","  mi = np.min(losses) - 0.05\n","  ma = np.max(losses) + 0.05\n","  plt.ylim([mi, ma])\n","  plt.legend()\n","  plt.show()\n","  n = \"lossPlot.png\"\n","  fig.savefig(path.join(SAVE, n))"],"metadata":{"id":"rnEvlcsxwTCP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Function that displays the ppl plot over epochs.\n",":param n_epochs: integer number of epochs performed\n",":param ppls: list containing all the losses over n_epochs\n","\"\"\"\n","def pplPlot(n_epochs, ppls):\n","  fig = plt.figure(figsize = (15, 10))\n","  plt.plot(n_epochs, ppls, 'blueviolet', label = \"PPL\")\n","  plt.title(\"Perplexity over epochs\")\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(\"Perplexity\")\n","  mi = np.min(ppls) - 10\n","  ma = np.max(ppls) + 10\n","  plt.ylim([mi, ma])\n","  plt.legend()\n","  plt.show()\n","  n = \"pplPlot.png\"\n","  fig.savefig(path.join(SAVE, n))"],"metadata":{"id":"QzcHQ4JDwU0N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Function that computes the words with the highest and lowest mean perplexity.\n","\"\"\"\n","def min_max_ppl():\n","  losses = np.array(read_words(path.join(SAVE, \"loss_per_word.txt\")), dtype = float)\n","  words = read_words(path.join(SAVE, \"output.txt\"))\n","\n","  cum_losses = np.zeros(len(trainCorpus.id2word)) # sum of the losses per word\n","  n_word = np.zeros(len(trainCorpus.id2word)) # numbers of words for each type of word in the trainCorpus\n","\n","  for idx, loss in enumerate(losses):\n","    w_id = trainCorpus.word2id[words[idx]] \n","    cum_losses[w_id] = cum_losses[w_id] + loss\n","    n_word[w_id] = n_word[w_id] + 1\n","\n","  # Since the train contains more words than the test (but not viceversa) some\n","  # elements in cum_losses and n_word will be 0.\n","  # Therefore to obtain the mean loss per word we have to exclude division by 0\n","  mean_losses = np.zeros(len(trainCorpus.id2word))\n","  for idx in range(len(mean_losses)):\n","    if n_word[idx] != 0:\n","      mean_losses[idx] = cum_losses[idx] / n_word[idx]\n","\n","  max_loss = np.max(mean_losses)\n","  p_max = np.argmax(mean_losses)\n","  word_max = words[p_max]\n","\n","  min_loss = np.min(mean_losses[mean_losses != 0.])\n","  p_min = np.argmin(mean_losses[mean_losses != 0.])\n","  word_min = words[p_min]\n","\n","  print(\"The word with the highest perplexity (\", np.exp(max_loss), \") is: \", word_max)\n","  print(\"The word with the lowest perplexity (\", min_loss, \") is: \", word_min)"],"metadata":{"id":"UueemK37wXFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def len_ppl():\n","  with open(path.join(SAVE, \"loss_per_word.txt\"), 'r') as f:\n","    sents = []\n","    for line in f:\n","      words = []\n","      for word in line.split():\n","        if float(word) != 0:\n","          words.append(word)\n","      \n","      if len(words) != 0:\n","        sents.append(words)\n","  f.close()\n","\n","  lengths = np.zeros(len(sents))\n","  means = np.zeros(len(sents))\n","  n = np.zeros(len(sents))\n","  for sent in sents:\n","    lengths[len(sent)] = len(sent)\n","    means[len(sent)] = means[len(sent)] + np.mean(np.array(sent, dtype = float))\n","    n[len(sent)] = n[len(sent)] + 1\n","\n","  lengths = lengths[lengths != 0]\n","  means = means[means != 0]\n","  n = n[n != 0]\n","  m = np.divide(means, n)\n","\n","  # Creation of the list containing a color of the bar for each class\n","  fill = []\n","  for i in range(len(lengths)):\n","    fill.append(np.random.rand(len(lengths) ,3))\n","\n","  # Visualization\n","  fig = plt.figure(figsize = (15, 20))\n","  ax1 = plt.subplot2grid(shape = (2, 1), loc = (0, 0))\n","  l_str = []\n","  for length in lengths:\n","    l_str.append(str(length))\n","  ax1.bar(l_str, np.exp(m), color = np.random.rand(len(lengths), 3))\n","  ax1.set_xlabel(\"Lengths\")\n","  ax1.set_ylabel(\"Mean perplexity\")\n","  ax1.set_title(\"Perplexiy per sentence's length\")\n","  plt.setp(ax1.get_xticklabels(), rotation=90)\n","\n","  ax2 = plt.subplot2grid(shape = (2, 1), loc = (1, 0))\n","  ax2.bar(l_str, n, color = np.random.rand(len(lengths), 3))\n","  ax2.set_ylabel(\"Number of occurrence\")\n","  ax2.set_xlabel(\"Lengths\")\n","  ax2.set_title(\"Number of occurrences of each sentence length\")\n","  plt.setp(ax2.get_xticklabels(), rotation=90)\n","\n","\n","  name = \"length_vs_ppl.png\"\n","  fig.savefig(path.join(SAVE, name))\n","  print(\"The sentences of length {} are the one with higher perplexity ({})\".format(lengths[np.argmax(m)], np.max(np.exp(m))))\n","  print(\"The sentences of length {} are the one with occur more often ({})\".format(lengths[np.argmax(n)], np.max(n)))\n","  print(\"The sentences of length {} are the one with lower perplexity ({})\".format(lengths[np.argmin(m)], np.min(np.exp(m))))\n","  print(\"The sentences of length {} are the one with occur less often ({})\".format(lengths[np.argmin(n)], np.min(n)))"],"metadata":{"id":"tKk9kgvOwbQm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Computation of the statistics"],"metadata":{"id":"9HrBrB9xw81w"}},{"cell_type":"code","source":["l = read_losses(path.join(SAVE, \"Losses/\", (\"train\" + str(RUNS - 1) + \".txt\"))) # read the losses of the last run\n","lossPlot(range(EPOCHS_I), l)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":621},"id":"JNcoqOlGwkGE","executionInfo":{"status":"ok","timestamp":1658344789715,"user_tz":-120,"elapsed":1257,"user":{"displayName":"Laura Corso","userId":"16642028059811970306"}},"outputId":"b0ee3887-8171-4562-8b2a-0fb37970ccb4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["pplPlot(range(EPOCHS_I), np.exp(l))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":621},"id":"5Kn5oFcFwpNq","executionInfo":{"status":"ok","timestamp":1658344790650,"user_tz":-120,"elapsed":941,"user":{"displayName":"Laura Corso","userId":"16642028059811970306"}},"outputId":"d4e0c5c3-51f3-43ac-bfd5-ab6d76fc78da"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["min_max_ppl()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"45xUafGVwtZp","executionInfo":{"status":"ok","timestamp":1658344809833,"user_tz":-120,"elapsed":832,"user":{"displayName":"Laura Corso","userId":"16642028059811970306"}},"outputId":"fbd03b59-d012-48f5-eb4c-2d87265a3e9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The word with the highest perplexity ( 131857360.33099522 ) is:  by\n","The word with the lowest perplexity ( 8.785339014139026e-05 ) is:  <unk>\n"]}]},{"cell_type":"code","source":["len_ppl()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xFhnsMpcwwsZ","executionInfo":{"status":"ok","timestamp":1658344793826,"user_tz":-120,"elapsed":2333,"user":{"displayName":"Laura Corso","userId":"16642028059811970306"}},"outputId":"c372564a-0da3-4e67-e222-1a7525f4a047"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The sentences of length 58.0 are the one with higher perplexity (631.968865171619)\n","The sentences of length 18.0 are the one with occur more often (155.0)\n","The sentences of length 1.0 are the one with lower perplexity (22.675967345927006)\n","The sentences of length 58.0 are the one with occur less often (1.0)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x1440 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Final.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a5b31acb04ab43029cdddc61f08294e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ca8190d13d34f5bb24d6d7a11bcb66c","IPY_MODEL_0606d82485924d988742fde689a6292d","IPY_MODEL_f64523a4ffaf4744b91c9b8a465ad2fb"],"layout":"IPY_MODEL_91513b5abd1844b990d9673d94b61521"}},"3ca8190d13d34f5bb24d6d7a11bcb66c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d9aa58099ba4b9ea6506a85051e9ebe","placeholder":"​","style":"IPY_MODEL_6359e7ae656c4b3295f7a7cf58e4d770","value":"Run: 100%"}},"0606d82485924d988742fde689a6292d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e2a2305453b4d1f927937ff59f1e2cc","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d04284e4ed74c6a87f820657f67b04d","value":5}},"f64523a4ffaf4744b91c9b8a465ad2fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd229ec61fb74341a83315fcd7cb0a92","placeholder":"​","style":"IPY_MODEL_9dc006b491694ad3844c2b3301670d3d","value":" 5/5 [1:04:35&lt;00:00, 774.78s/it]"}},"91513b5abd1844b990d9673d94b61521":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d9aa58099ba4b9ea6506a85051e9ebe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6359e7ae656c4b3295f7a7cf58e4d770":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e2a2305453b4d1f927937ff59f1e2cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d04284e4ed74c6a87f820657f67b04d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd229ec61fb74341a83315fcd7cb0a92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dc006b491694ad3844c2b3301670d3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11f601445ce246198f47891443e6fcb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08a0ca37fccb426585a6a0346860c551","IPY_MODEL_6e771058775540de8d8f4f2eb1c5ab14","IPY_MODEL_0f9e0185f8284db6a1c366c5e06a776a"],"layout":"IPY_MODEL_5cd8f2f603794cfcb31dff32452eb1ff"}},"08a0ca37fccb426585a6a0346860c551":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22c8bdfda0454fab9ab98c36d1b4ce91","placeholder":"​","style":"IPY_MODEL_c1162c688a4e469f8d65cfc897c30f23","value":"Epoch: 100%"}},"6e771058775540de8d8f4f2eb1c5ab14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5fcf47f36f04ad9ab7e984a0c969aef","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f44b93323ecf482d82111ccb4127e407","value":30}},"0f9e0185f8284db6a1c366c5e06a776a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c85e26f597b54ec2898fae965437454a","placeholder":"​","style":"IPY_MODEL_a4cb053ed3884127b1bbce232ba42d78","value":" 30/30 [12:51&lt;00:00, 25.74s/it]"}},"5cd8f2f603794cfcb31dff32452eb1ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22c8bdfda0454fab9ab98c36d1b4ce91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1162c688a4e469f8d65cfc897c30f23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5fcf47f36f04ad9ab7e984a0c969aef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f44b93323ecf482d82111ccb4127e407":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c85e26f597b54ec2898fae965437454a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4cb053ed3884127b1bbce232ba42d78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67cefc0bd22c4e43acef97fd01391938":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_380d60f2e2184d17b4b57021f0f1e6f8","IPY_MODEL_c8f1fdaf425b4bf9b8420a8be9da04c9","IPY_MODEL_9dc242920f4048c884a1d378843bacbf"],"layout":"IPY_MODEL_73f9007c1ca24eba8df6f7f69a8a0d95"}},"380d60f2e2184d17b4b57021f0f1e6f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2261b9b335614e2da9bd4da8ffafa72a","placeholder":"​","style":"IPY_MODEL_272c62cf12634d7d8994e14bec74ea50","value":"Epoch: 100%"}},"c8f1fdaf425b4bf9b8420a8be9da04c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_092e712fe1034f35bd51a33304afc334","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ef7373be9e1424cbb9c8cbf22334d16","value":30}},"9dc242920f4048c884a1d378843bacbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb7d2f4880a34de3bedca81f4de903fc","placeholder":"​","style":"IPY_MODEL_35d8c8b1570a4fafba78a7eea3317e03","value":" 30/30 [12:52&lt;00:00, 25.69s/it]"}},"73f9007c1ca24eba8df6f7f69a8a0d95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2261b9b335614e2da9bd4da8ffafa72a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"272c62cf12634d7d8994e14bec74ea50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"092e712fe1034f35bd51a33304afc334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ef7373be9e1424cbb9c8cbf22334d16":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb7d2f4880a34de3bedca81f4de903fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35d8c8b1570a4fafba78a7eea3317e03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9567402147654078ac9c8a20952b500f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21a6b1750bc64d49847c4c8b0bbc7dfe","IPY_MODEL_868ffa7675d347099a8598118ebe3905","IPY_MODEL_b069805e2ad0417a96abeea579de7377"],"layout":"IPY_MODEL_170d8020172b403796299a40b63831e8"}},"21a6b1750bc64d49847c4c8b0bbc7dfe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36caec4fb8594d46997583f99cf51089","placeholder":"​","style":"IPY_MODEL_674320d146d3469eb3a3930b61731670","value":"Epoch: 100%"}},"868ffa7675d347099a8598118ebe3905":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da293482dc174e74814740f828895e33","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b4a2c20220b4f3fbd6028d2bfc4f651","value":30}},"b069805e2ad0417a96abeea579de7377":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1fee3616a8f44b5aac60f3863fd6555","placeholder":"​","style":"IPY_MODEL_93a578320f4d4888a1abaa409373887a","value":" 30/30 [12:51&lt;00:00, 25.65s/it]"}},"170d8020172b403796299a40b63831e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36caec4fb8594d46997583f99cf51089":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"674320d146d3469eb3a3930b61731670":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da293482dc174e74814740f828895e33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b4a2c20220b4f3fbd6028d2bfc4f651":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1fee3616a8f44b5aac60f3863fd6555":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93a578320f4d4888a1abaa409373887a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f359a0382adf4b2994bac365d322151d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_37b61158bf8542f389d12ab54434229f","IPY_MODEL_918f823c1aaf4e8d9ec7667ade950a90","IPY_MODEL_663cd2a1a8de447e89f5a647005e07c9"],"layout":"IPY_MODEL_4478103761464fde8aeab390f76b893d"}},"37b61158bf8542f389d12ab54434229f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bba69bb31b164245b94e400df89ad38b","placeholder":"​","style":"IPY_MODEL_202d4c0735f7453d86c386f2d76bff72","value":"Epoch: 100%"}},"918f823c1aaf4e8d9ec7667ade950a90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f688c1bb9bb44099891f9e660c19662","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ee15f5f7e6f482eaec01c6504f2658e","value":30}},"663cd2a1a8de447e89f5a647005e07c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8caf0ecf431d48b586e4aa5234d9f25d","placeholder":"​","style":"IPY_MODEL_64e6ad8513d446c5bdc8cd9dba310029","value":" 30/30 [12:52&lt;00:00, 25.63s/it]"}},"4478103761464fde8aeab390f76b893d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bba69bb31b164245b94e400df89ad38b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"202d4c0735f7453d86c386f2d76bff72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f688c1bb9bb44099891f9e660c19662":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ee15f5f7e6f482eaec01c6504f2658e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8caf0ecf431d48b586e4aa5234d9f25d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e6ad8513d446c5bdc8cd9dba310029":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"155ee9bb763c4193b3291a938fe1992a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbd3a0483bbe43a689d80f27a2d71a23","IPY_MODEL_a1ada44b7f0c4cb1b288df3b3f71960d","IPY_MODEL_6bf57a0fabde4281a6ddefe1cefa5834"],"layout":"IPY_MODEL_56730a83d32c4fee9c016c096fd9ccd7"}},"fbd3a0483bbe43a689d80f27a2d71a23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_860d999cfef0419ba2deb61692c739a9","placeholder":"​","style":"IPY_MODEL_77c419015c8a4ba58a151a1a9977145b","value":"Epoch: 100%"}},"a1ada44b7f0c4cb1b288df3b3f71960d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_743e5d7df44044b194f68ffa28e0c695","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e6133fc324849dc8d282b18dcf0c9b8","value":30}},"6bf57a0fabde4281a6ddefe1cefa5834":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ed832030b5943b3a1b9d9696689dba8","placeholder":"​","style":"IPY_MODEL_aa80dc3625f24689bdea7f1947af3708","value":" 30/30 [12:55&lt;00:00, 25.91s/it]"}},"56730a83d32c4fee9c016c096fd9ccd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"860d999cfef0419ba2deb61692c739a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77c419015c8a4ba58a151a1a9977145b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"743e5d7df44044b194f68ffa28e0c695":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e6133fc324849dc8d282b18dcf0c9b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ed832030b5943b3a1b9d9696689dba8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa80dc3625f24689bdea7f1947af3708":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"298435ec7dd843dd9a3342845b118754":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe0e2d5b6d9942af9db79d53bb79c28a","IPY_MODEL_913eddd4ac0e4df7af30a9a4bb0b2f0f","IPY_MODEL_e9d8bee9e7764ed9902d4e8126c5b629"],"layout":"IPY_MODEL_9e03acb83b044de39a9543c091a4a4f2"}},"fe0e2d5b6d9942af9db79d53bb79c28a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_879ec6b7fd0a4279ad042fa6e8977af2","placeholder":"​","style":"IPY_MODEL_72cc716bf16b4b57992dfbaf44466c36","value":"Run: 100%"}},"913eddd4ac0e4df7af30a9a4bb0b2f0f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a499a4ae3a5482aa109282f7d1f6422","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13f4814106514efa8e51756b7883b915","value":5}},"e9d8bee9e7764ed9902d4e8126c5b629":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59bc24312b2b4d77935850e606b32856","placeholder":"​","style":"IPY_MODEL_cb2cd2932cd84acca0b37d7c2a970760","value":" 5/5 [1:37:10&lt;00:00, 1165.28s/it]"}},"9e03acb83b044de39a9543c091a4a4f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"879ec6b7fd0a4279ad042fa6e8977af2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72cc716bf16b4b57992dfbaf44466c36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a499a4ae3a5482aa109282f7d1f6422":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13f4814106514efa8e51756b7883b915":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"59bc24312b2b4d77935850e606b32856":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb2cd2932cd84acca0b37d7c2a970760":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0d8a32214ef438aa2d45299a788c848":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_10a86d60424f433baa4926e3743aec1b","IPY_MODEL_5b90c9eea6ed4f8bacc5f2721737d16e","IPY_MODEL_b687bcb065004a459288dcd802d27a87"],"layout":"IPY_MODEL_0fca38423edc41e4b77301434a3b0a64"}},"10a86d60424f433baa4926e3743aec1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85e82f958c894177b64d0e1a6c315cc7","placeholder":"​","style":"IPY_MODEL_98a7a424579b437f998e88194f13e925","value":"Epoch: 100%"}},"5b90c9eea6ed4f8bacc5f2721737d16e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_455ca76addc040f79a7523f3c1e8b125","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bd32810c4c64ec6b2f7b8857c48faaa","value":40}},"b687bcb065004a459288dcd802d27a87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e106598ace640a1ac8651ff2f1dda88","placeholder":"​","style":"IPY_MODEL_af7aee7f27b24a838c9a240f0113556b","value":" 40/40 [19:23&lt;00:00, 29.01s/it]"}},"0fca38423edc41e4b77301434a3b0a64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85e82f958c894177b64d0e1a6c315cc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98a7a424579b437f998e88194f13e925":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"455ca76addc040f79a7523f3c1e8b125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bd32810c4c64ec6b2f7b8857c48faaa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e106598ace640a1ac8651ff2f1dda88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af7aee7f27b24a838c9a240f0113556b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"430c35b33945400a887cb598b36e1faa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa0f8a9ac6a34a39ae2d613fa500fb34","IPY_MODEL_c8128784d6c5485fb16d8787e94a5c47","IPY_MODEL_c5b05b4eebe841a9b1afaa99967bf410"],"layout":"IPY_MODEL_3ae3240d01fa419091a1cce7b0264633"}},"aa0f8a9ac6a34a39ae2d613fa500fb34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b194a16d1bc1404eb49877f7be1a42b5","placeholder":"​","style":"IPY_MODEL_25666c93ad014582ae956be0ca81a980","value":"Epoch: 100%"}},"c8128784d6c5485fb16d8787e94a5c47":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff0b9f91145a4a15b9629942c43276b4","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03631c08750e41daa9a087f268ce05f2","value":40}},"c5b05b4eebe841a9b1afaa99967bf410":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c6ca64d794a4e26bb983da824b39950","placeholder":"​","style":"IPY_MODEL_43a6f60e280c4c35a6794270dba1444a","value":" 40/40 [19:23&lt;00:00, 28.98s/it]"}},"3ae3240d01fa419091a1cce7b0264633":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b194a16d1bc1404eb49877f7be1a42b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25666c93ad014582ae956be0ca81a980":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff0b9f91145a4a15b9629942c43276b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03631c08750e41daa9a087f268ce05f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c6ca64d794a4e26bb983da824b39950":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43a6f60e280c4c35a6794270dba1444a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a776f4cd02ad419e8ba1f10c4be53bfc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07ada2015c104e0aa966e3322721ecfe","IPY_MODEL_51460f5b41ea475795afe7e63fe291da","IPY_MODEL_2de5fb2ac52e4659874760e363599247"],"layout":"IPY_MODEL_3c10091b396b402288dcdf5ac3098fcd"}},"07ada2015c104e0aa966e3322721ecfe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04d5dc5f24054e15bc29bf1a84ec7aba","placeholder":"​","style":"IPY_MODEL_b420d4bbff004c939037f02d76fa445b","value":"Epoch: 100%"}},"51460f5b41ea475795afe7e63fe291da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98c0218cd0834aa9bef016a957dcccb3","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_082bc469a79d406688f6650bc69dde6e","value":40}},"2de5fb2ac52e4659874760e363599247":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51c1c7f5c8564765a6d5d86dd47a6f68","placeholder":"​","style":"IPY_MODEL_cc810cebed9942078990f283610e4816","value":" 40/40 [19:20&lt;00:00, 28.97s/it]"}},"3c10091b396b402288dcdf5ac3098fcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d5dc5f24054e15bc29bf1a84ec7aba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b420d4bbff004c939037f02d76fa445b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98c0218cd0834aa9bef016a957dcccb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"082bc469a79d406688f6650bc69dde6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"51c1c7f5c8564765a6d5d86dd47a6f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc810cebed9942078990f283610e4816":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f22bb5490f7a4a7ebb259844e34fdb36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d8abed111544a41b967301d8145425b","IPY_MODEL_755c376ef4d64775b2bcc975b943937e","IPY_MODEL_69a4952f5bdb42ab92648020e3c7e5d1"],"layout":"IPY_MODEL_c2f037558e864a0383970e9470379455"}},"4d8abed111544a41b967301d8145425b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f03bc8ad8a045fe9e179013fda02631","placeholder":"​","style":"IPY_MODEL_9b6cfacf20f24ab89207e3a81e243e18","value":"Epoch: 100%"}},"755c376ef4d64775b2bcc975b943937e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_831b55e1bf0b4f3790b73f908bbe3df2","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_300a5a02e7e442e3811dd02bdefb3414","value":40}},"69a4952f5bdb42ab92648020e3c7e5d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a5fe464f66145f2bcebb80cf3b48369","placeholder":"​","style":"IPY_MODEL_30a9d4693cd94de080be200ba99bf482","value":" 40/40 [19:21&lt;00:00, 28.96s/it]"}},"c2f037558e864a0383970e9470379455":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f03bc8ad8a045fe9e179013fda02631":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b6cfacf20f24ab89207e3a81e243e18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"831b55e1bf0b4f3790b73f908bbe3df2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"300a5a02e7e442e3811dd02bdefb3414":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a5fe464f66145f2bcebb80cf3b48369":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30a9d4693cd94de080be200ba99bf482":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"825e714725df4b26997fe2ac67dbc149":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_150bf6df0a4245b884db8dfd28a3ecd1","IPY_MODEL_97d02fe8e10f47469fc74fc1a3894543","IPY_MODEL_701b3aa3d91247599e7b303d35b19c81"],"layout":"IPY_MODEL_1aed861e240041eeab083b4e442a7619"}},"150bf6df0a4245b884db8dfd28a3ecd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48bcb4f3503f4ed5af4690541fa73f7d","placeholder":"​","style":"IPY_MODEL_d2430f0eea50470db6a98060e38451ee","value":"Epoch: 100%"}},"97d02fe8e10f47469fc74fc1a3894543":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_700eb13d764447a2b32c0bd83f341787","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36244f7924d54c7da5c05602087b721d","value":40}},"701b3aa3d91247599e7b303d35b19c81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56957c1e88fc4f499942c339920f563f","placeholder":"​","style":"IPY_MODEL_b00dce6b6b314cd1b26e228799c84db1","value":" 40/40 [19:22&lt;00:00, 29.07s/it]"}},"1aed861e240041eeab083b4e442a7619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48bcb4f3503f4ed5af4690541fa73f7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2430f0eea50470db6a98060e38451ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"700eb13d764447a2b32c0bd83f341787":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36244f7924d54c7da5c05602087b721d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56957c1e88fc4f499942c339920f563f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b00dce6b6b314cd1b26e228799c84db1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}